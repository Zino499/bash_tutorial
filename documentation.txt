		THE BOURNE AGAIN SHELL


                              The Bourne Shell: /bin/sh 
The shell is one of the most important parts of a Unix system. A shell is a program
that runs commands, like the ones that users enter. The shell also serves as a small programming
environment. Unix programmers often break common tasks into little components and use
the shell to manage tasks and piece things together. 

Many important parts of the system are actually shell scripts—text files that contain a sequence of shell 
commands. If you’ve worked with MS-DOS previously, you can think of shell scripts as very powerful .BAT 
files. Because they’re important, Chapter 11 is devoted entirely to shell scripts. 

As you progress through this book and gain practice, you’ll add to your knowledge of manipulating
commands using the shell. One of the best things about the shell is that if you make a mistake, you can
easily see what you typed to find out what went wrong, and then try again.
 
There are many different Unix shells, but all derive several of their features from the Bourne shell
(/bin/sh), a standard shell developed at Bell Labs for early versions of Unix. Every Unix system needs
the Bourne shell in order to function correctly, as you will see throughout this book. 

Linux uses an enhanced version of the Bourne shell called bash or the “Bourne-again” shell. The bash shell 
is the default shell on most Linux distributions, and /bin/sh is normally a link to bash on a Linux system.
You should use the bash shell when running the examples in this book. 

NOTE 
You may not have bash as your default shell if you’re using this chapter as a guide for a Unix 
account at an organization where you’re not the system administrator. You can change your shell 
with chsh or ask your system administrator for help.

                                The Shell Window 
After logging in, open a shell window (often referred to as a terminal). The easiest way to do so from a GUI
like Gnome or Ubuntu’s Unity is to open a terminal application, which starts a shell inside a new window.
Once you’ve opened a shell, it should display a prompt at the top that usually ends with a dollar sign ($).
On Ubuntu, that prompt should look like name@host:path$, and on Fedora, it’s [name@host path]$. If you’re familiar
with Windows, the shell window will look something like a DOS command prompt; the Terminal application in
OS X is essentially the same as a Linux shell window. This book contains many commands that you will type at a shell prompt.
They all begin with a single $ to denote the shell prompt. For example, type this command
(just the part in bold, not the $) and press ENTER: 

$ echo Hello there. 


                                         NOTE 
Many shell commands in this book start with #. You should run these as the superuser (root). These commands
usually require extra caution. Now enter this command: 


$ cat /etc/passwd 

This command displays the contents of the /etc/passwd system information file and then returns your shell prompt.
Don’t worry about what this file does right now; you’ll learn all about it later, in Chapter 7


                                          cat 
The cat command is one of the easiest Unix commands to understand; it simply outputs the contents of one or more files.
The general syntax of the cat command is as follows: 

$ cat file1 file2 

When you run this command, cat prints the contents of file1, file2, and any other files that you specify 
(denoted by ...), and then exits. The command is called cat because it performs concatenation when it prints
the contents of more than one file.


                                   Standard Input and Standard Output 
We’ll use cat to briefly explore Unix input and output (I/O). Unix processes use I/O streams to read and write data.
Processes read data from input streams and write data to output streams. Streams are very flexible. For example, the
source of an input stream can be a file, a device, a terminal, or even the output stream from another process. 

To see an input stream at work, enter cat (with no filenames) and press ENTER. This time, you won’t get your shell prompt
back because cat is still running. Now type anything and press ENTER at the end of each line. The cat command repeats
any line that you type. Once you’re sufficiently bored, press CTRL-D on an empty line to terminate cat and return to the shell prompt. 

The reason cat adopted an interactive behavior has to do with streams. Because you did not specify an input filename, cat
read from the standard input stream provided by the Linux kernel rather than a stream connected to a file.
In this case, the standard input was connected to the terminal in which you ran cat. 


                                            NOTE 
Pressing CTRL-D on an empty line stops the current standard input entry from the terminal (and often terminates a program).
Don’t confuse this with CTRL-C, which terminates a program regardless of its input or output. Standard output is similar.
The kernel gives each process a standard output stream where it can write its output. The cat command always writes its
output to the standard output. When you ran cat in the terminal, the standard output was connected to that terminal, so
that’s where you saw the output. 

Standard input and output are often abbreviated as stdin and stdout. Many commands operate as cat does; if you don’t specify
an input file, the command reads from stdin. Output is a little different. Some commands (like cat) send output only to
stdout, but others have the option to send output directly to files. 

There is a third standard I/O stream called standard error. You’ll see it in 2.14.1 Standard Error. 
One of the best features of standard streams is that you can easily manipulate them to read and write
to places other than the terminal, as you’ll learn in 2.14 Shell Input and Output. In particular, you’ll
learn how to connect streams to files and other processes.


                                       Basic Commands 
Now let’s look at some more Unix commands. Most of the following programs take multiple arguments, and some have so many
options and formats that an unabridged listing would be pointless. This is a simplified list of the basic commands; you
don’t need all of the details just yet.


                                          ls 
The ls command lists the contents of a directory. The default is the current directory. Use ls -l for a 
detailed (long) listing and ls -F to display file type information. (For more on the file types and permissions
displayed in the left column below, see 2.17 File Modes and Permissions.) Here is a sample long listing; it includes
the owner of the file (column 3), the group (column 4), the file size (column 5), and the modification date/time
(between column 5 and the filename):



                                           cp 
In its simplest form, cp copies files. For example, to copy file1 to file2, enter this: 

$ cp file1 file2 

To copy a number of files to a directory (folder) named dir, try this instead: 

$ cp file1 ... fileN dir 

                                          mv 
The mv (move) command is like cp. In its simplest form, it renames a file. For example, to rename file1 to 
file2, enter this: 

$ mv file1 file2 

You can also use mv to move a number of files to a different directory: 

$ mv file1 ... fileN dir 


                                         touch 
The touch command creates a file. If the file already exists, touch does not change it, but it does update 
the file’s modification time stamp printed with the ls -l command. For example, to create an empty file, 
enter this: 

$ touch file 

Then run ls -l on that file. You should see output like the following, where the date and time ➊ indicate 
when you ran touch: 


$ ls -l file 
-rw-r--r-- 1 juser users 0 May 21 18:32➊ file 

                                             rm 
To delete (remove) a file, use rm. After you remove a file, it’s gone from your system and generally cannot be undeleted. 

$ rm file 

                                            echo 
The echo command prints its arguments to the standard output: 

$ echo Hello again. 

Hello again. 

The echo command is very useful for finding expansions of shell globs (“wildcards” such as *) and variables (such as $HOME), which
you will encounter later in this chapter.



                                         Navigating Directories 
Unix has a directory hierarchy that starts at /, sometimes called the root directory. The directory separator is
the slash (/), not the backslash (\). There are several standard subdirectories in the root directory, such
as /usr, as you’ll learn in 2.19 Linux Directory Hierarchy Essentials. 

When you refer to a file or directory, you specify a path or pathname. When a path starts with / (such as 
/usr/lib), it’s a full or absolute path.
 
A path component identified by two dots (..) specifies the parent of a directory. For example, if you’re
working in /usr/lib, the path .. would refer to /usr. Similarly, ../bin would refer to /usr/bin.
 
One dot (.) refers to the current directory; for example, if you’re in /usr/lib, the path . is still /usr/lib, and
./X11 is /usr/lib/X11. You won’t have to use . very often because most commands default to the current directory if
a path doesn’t start with / (you could just use X11 instead of ./X11 in the preceding example). 

A path not beginning with / is called a relative path. Most of the time, you’ll work with relative pathnames, 
because you’ll already be in the directory you need to be in or somewhere close by. Now that you have a sense
of the basic directory mechanics, here are some essential directory commands.



                                            cd 
The current working directory is the directory that a process (such as the shell) is currently in. The cd 
command changes the shell’s current working directory: 

$ cd dir
 
If you omit dir, the shell returns to your home directory, the directory you started in when you first logged in. 

                                           mkdir 
The mkdir command creates a new directory dir: 

$ mkdir dir 

                                           rmdir 
The rmdir command removes the directory dir: 

$ rmdir dir 

If dir isn’t empty, this command fails. However, if you’re impatient, you probably don’t want to laboriously delete
all the files and subdirectories inside dir first. You can use rm -rf dir to delete a directory and its contents, but
be careful! This is one of the few commands that can do serious damage, especially if you run it as the superuser.
The -r option specifies recursive delete to repeatedly delete everything inside dir, and -f forces the delete operation.
Don’t use the -rf flags with globs such as a star (*). And above all, always double-check your command before you run it.


                                      Shell Globbing (Wildcards) 
The shell can match simple patterns to file and directory names, a process known as globbing. This is similar to the
concept of wildcards in other systems. The simplest of these is the glob character *, which tells the shell 
to match any number of arbitrary characters. For example, the following command prints a list of files in the current directory:
 
$ echo * 

The shell matches arguments containing globs to filenames, substitutes the filenames for those arguments, and then runs
the revised command line. The substitution is called expansion because the shell substitutes all 
matching filenames. Here are some ways to use * to expand filenames: 

o at* expands to all filenames that start with at. 

o *at expands to all filenames that end with at.

o at expands to all filenames that contain at. 

If no files match a glob, the shell performs no expansion, and the command runs with literal characters such as *.
For example, try a command such as echo *dfkdsafh. 

                                                       NOTE 
If you’re used to MS-DOS, you might instinctively type . to match all files. Break this habit now. In Linux and other
versions of Unix, you must use * to match all files. In the Unix shell, . matches only files and directories that contain
the dot (.) character in their names. Unix filenames do not need extensions and often do not carry them. 

Another shell glob character, the question mark (?), instructs the shell to match exactly one arbitrary character.
For example, b?at matches boat and brat. 

If you don’t want the shell to expand a glob in a command, enclose the glob in single quotes (''). For example, the command
echo '*' prints a star. You will find this handy for a few of the commands described in the next section, such as grep and find.
(You’ll learn more much about quoting in 11.2 Quoting and Literals.) 

                                                       NOTE 
It is important to remember that the shell performs expansions before running commands, and only then. Therefore, if a * makes
it to a command without expanding, the shell will do nothing more with it; it’s up to the command to decide what it wants to do.

There is more to a modern shell’s pattern-matching capabilities, but * and ? are what you need to know now.


                                               intermediate Commands 
The following sections describe the most essential intermediate Unix commands. 

                                                     grep 
The grep command prints the lines from a file or input stream that match an expression. For example, to print the lines
in the /etc/passwd file that contain the text root, enter this: 

$ grep root /etc/passwd 

The grep command is extraordinarily handy when operating on multiple files at once because it prints the filename
in addition to the matching line. For example, if you want to check every file in /etc that contains the word
root, you could use this command: 

$ grep root /etc/* 

Two of the most important grep options are -i (for case-insensitive matches) and -v (which inverts the 
search, that is, prints all lines that don’t match). There is also a more powerful variant called egrep
(which is just a synonym for grep -E). grep understands patterns known as regular expressions that are grounded
in computer science theory and are very common in Unix utilities. Regular expressions are more powerful than wildcard-style
patterns, and they have a different syntax. There are two important things to remember about regular expressions: 

o .* matches any number of characters (like the * in wildcards).
 
o . matches one arbitrary character. 



                                                       NOTE 
The grep(1) manual page contains a detailed description of regular expressions, but it can be a little difficult to read.
To learn more, you can read Mastering Regular Expressions, 3rd edition (O’Reilly, 2006), or see the regular expressions
chapter of Programming Perl, 4th edition.



                                                  less 
The less command comes in handy when a file is really big or when a command’s output is long and scrolls off the top of the screen. 

To page through a big file like /usr/share/dict/words, use the command less /usr/share/dict/words. When running less, you’ll
see the contents of the file one screenful at a time. Press the spacebar to go forward in the file and the b key to skip
back one screenful. To quit, type q. 

                                                  NOTE 
The less command is an enhanced version of an older program named more. Most Linux desktops and servers have less, but
it’s not standard on many embedded systems and other Unix systems. So if you ever run into a situation when you can’t
use less, try more. 

You can also search for text inside less. For example, to search forward for a word, type /word, and to search
backward, use ?word. When you find a match, press n to continue searching. 

As you’ll learn in 2.14 Shell Input and Output, you can send the standard output of nearly any program directly
to another program’s standard input. This is exceptionally useful when you have a command with a lot of output to sift through
and you’d like to use something like less to view the output. Here’s an example of sending the output of a grep command to less: 

$ grep ie /usr/share/dict/words | less 

Try this command out for yourself. You’ll probably use less like this a lot.



                                                           pwd 
The pwd (print working directory) program simply outputs the name of the current working directory. You may be
wondering why you need this when most Linux distributions set up accounts with the current working directory in the prompt.

There are two reasons. First, not all prompts include the current working directory, and you may even want to get rid of
it in your own prompt because it takes up a lot of space. If you do so, you need pwd. 

Second, the symbolic links that you’ll learn about in 2.17.2 Symbolic Links can sometimes obscure the true full path of
the current working directory. You’ll use pwd -P to eliminate this confusion. 

                                                          diff 
To see the differences between two text files, use diff: 

$ diff file1 file2 

Several options can control the format of the output, and the default output format is often the most comprehensible
for human beings. However, most programmers prefer the output from diff -u when they need to send the output to someone
else because automated tools can make better use of it. 

                                                         file 
If you see a file and are unsure of its format, try using the file command to see if the system can guess: 

$ file file 

You may be surprised by how much this innocent-looking command can do.



                                                    find and locate 
It’s frustrating when you know that a certain file is in a directory tree somewhere but you just don’t know 
where. Run find to find file in dir: 

$ find dir -name file -print 

Like most programs in this section, find is capable of some fancy stuff. However, don’t try options such as 
-exec before you know the form shown here by heart and why you need the -name and -print options. 

The find command accepts special pattern-matching characters such as *, but you must enclose them in 
single quotes ('*')to protect the special characters from the shell’s own globbing feature.
(Recall from 2.4.4 Shell Globbing (Wildcards) that the shell expands globs before running commands.)

Most systems also have a locate command for finding files. Rather than searching for a file in real time, locate searches
an index that the system builds periodically. Searching with locate is much faster than find, but if the file you’re looking for
is newer than the index, locate won’t find it.

                                              head and tail 
To quickly view a portion of a file or stream of data, use the head and tail commands. For example, head 
/etc/passwd shows the first 10 lines of the password file, and tail /etc/passwd shows the last 10 
lines. 

To change the number of lines to display, use the -n option, where n is the number of lines you want to see 
(for example, head -5 /etc/passwd). To print lines starting at line n, use tail +n. 

                                                     sort
The sort command quickly puts the lines of a text file in alphanumeric order. If the file’s lines start with 
numbers and you want to sort in numerical order, use the -n option. The -r option reverses the order of the 
sort.



                                           Changing Your Password and Shell 
Use the passwd command to change your password. You’ll be asked for your old password and then prompted for your
new password twice. Choose a password that does not include real words in any language and don’t try to combine words. 

One of the easiest ways to create a good password is to pick a sentence, produce an acronym from it, and then
modify the acronym with a number or some punctuation. Then all you need to do is remember the sentence. 
You can change your shell with the chsh command (to an alternative such as ksh or tcsh), but keep in 
mind that this book assumes that you’re running bash. 

                                                    Dot Files 
Change to your home directory, take a look around with ls, and then run ls -a. Do you see the difference 
in the output? When you run ls without the -a, you won’t see the configuration files called dot files. These
are files and directories whose names begin with a dot (.). Common dot files are .bashrc and .login, and there are dot
directories, too, such as .ssh.

There is nothing special about dot files or directories. Some programs don’t show them by default so that you
won’t see a complete mess when listing the contents of your home directory. For example, ls doesn’t list
dot files unless you use the -a option. In addition, shell globs don’t match dot files unless you
explicitly use a pattern such as .*. 

                                                    NOTE 
You can run into problems with globs because .* matches . and .. (the current and parent directories). You
may wish to use a pattern such as .[^.]* or .??* to get all dot files except the current and parent directories.


                                    Environment and Shell Variables 
The shell can store temporary variables, called shell variables, containing the values of text strings.
Shell variables are very useful for keeping track of values in scripts, and some shell variables control the
way the shell behaves. (For example, the bash shell reads the PS1 variable before displaying the prompt.) 

To assign a value to a shell variable, use the equal sign (=). Here’s a simple example: 

$ STUFF=blah 

The preceding example sets the value of the variable named STUFF to blah. To access this variable, use 
$STUFF (for example, try running echo $STUFF). You’ll learn about the many uses of shell variables in 
Chapter 11. 

An environment variable is like a shell variable, but it’s not specific to the shell. All processes on Unix
systems have environment variable storage. The main difference between environment and shell variables is that
the operating system passes all of your shell’s environment variables to programs that the shell runs, whereas shell 
variables cannot be accessed in the commands that you run. 

Assign an environment variable with the shell’s export command. For example, if you’d like to make the $STUFF
shell variable into an environment variable, use the following: 

$ STUFF=blah 

$ export STUFF 

Environment variables are useful because many programs read them for configuration and options. For 
example, you can put your favorite less command-line options in the LESS environment variable, and less
will use those options when you run it. (Many manual pages contain a section marked ENVIRONMENT that
describes these variables.)


                                              The Command Path 
PATH is a special environment variable that contains the command path (or path for short). A command path is a
list of system directories that the shell searches when trying to locate a command. For example, when you run ls,
the shell searches the directories listed in PATH for the ls program. If programs with the same name 
appear in several directories in the path, the shell runs the first matching program. 

If you run echo $PATH, you’ll see that the path components are separated by colons (:). For example: 

$ echo $PATH 

/usr/local/bin:/usr/bin:/bin 
To tell the shell to look in more places for programs, change the PATH environment variable. For example, by
using this command, you can add a directory dir to the beginning of the path so that the shell looks in dir before
looking in any of the other PATH directories. 

$ PATH=dir:$PATH 

Or you can append a directory name to the end of the PATH variable, causing the shell to look in dir last: 

$ PATH=$PATH:dir 

                                                          NOTE 
Be careful when modifying the path because you can accidentally wipe out your entire path if you mistype $PATH.
If this happens, don’t panic! The damage isn’t permanent; you can just start a new shell. (For a lasting effect,
you need to mistype it when editing a certain configuration file, and even then it isn’t difficult to rectify.)
One of the easiest ways to return to normal is to close the 
current terminal window and start another.


                                                Special Characters 
When discussing Linux with others, you should know a few names for some of the special characters that 
you’ll encounter. If you’re amused by this sort of thing, see the “Jargon File” 
(http://www.catb.org/jargon/html/) or its printed companion, The New Hacker’s Dictionary (MIT Press, 1996). 
Table 2-1 describes a select set of the special characters, many of which you’ve already seen in this chapter. 
Some utilities, such as the Perl programming language, use almost all of these special characters! (Keep in 
mind that these are the American names for the characters.)


                                          Character Name(s) Uses 
* asterisk, star Regular expression, glob character 

. dot Current directory, file/hostname delimiter 

! bang Negation, command history 

| pipe Command pipes 

/ (forward) slash Directory delimiter, search command 

\ backslash Literals, macros (never directories) 

$ dollar Variable denotation, end of line 

' tick, (single) quote Literal strings 

` backtick, backquote Command substitution 

" double quote Semi-literal strings 

^ caret Negation, beginning of line 

~ tilde, squiggle Negation, directory shortcut 

# hash, sharp, pound Comments, preprocessor, substitutions 

[ ] (square) brackets Ranges


                                        Character Name(s) Uses 
{ } braces, (curly) brackets Statement blocks, ranges 
_ underscore, under Cheap substitute for a space


You will often see control characters marked with a caret; for example, ^C for ctrl-c. 2.11 Command-Line Editing 
As you play with the shell, notice that you can edit the command line using the left and right arrow keys, as 
well as page through previous commands using the up and down arrows. This is standard on most Linux systems. 
However, it’s a good idea to forget about the arrow keys and use control key sequences instead. If you learn 
the ones listed in Table 2-2, you’ll find that you’re better able to enter text in the many Unix programs that 
use these standard keystrokes.


                                 Keystroke Action 
CTRL-B Move the cursor left 
CTRL-F Move the cursor right 
CTRL-P View the previous command (or move the cursor up) 
CTRL-N View the next command (or move the cursor down) 
CTRL-A Move the cursor to the beginning of the line 
CTRL-E Move the cursor to the end of the line 
CTRL-W Erase the preceding word 
CTRL-U Erase from cursor to beginning of line 
CTRL-K Erase from cursor to end of line 
CTRL-Y Paste erased text (for example, from CTRL-U)



                                              Text Editors 
Speaking of editing, it’s time to learn an editor. To get serious with Unix, you must be able to edit text
files without damaging them. Most parts of the system use plaintext configuration files (like the ones in /etc).
It’s not difficult to edit files, but you will do it so often that you need a powerful tool for the job. 
You should try to learn one of the two de facto standard Unix text editors, vi and Emacs. Most Unix wizards
are religious about their choice of editor, but don’t listen to them. Just choose for yourself. If you
choose one that matches the way that you work, you’ll find it easier to learn. Basically, the choice
comes down to this: 

o If you want an editor that can do almost anything and has extensive online help, and you don’t mind
doing some extra typing to get these features, try Emacs. 

o If speed is everything, give vi a shot; it “plays” a bit like a video game. 

Learning the vi and Vim Editors: Unix Text Processing, 7th edition (O’Reilly, 2008) can tell
you everything you need to know about vi. For Emacs, use the online tutorial: Start Emacs,
press CTRL-H, and then type T. Or read GNU Emacs Manual (Free Software Foundation, 2011). 
You might be tempted to experiment with a friendlier editor when you first start out, such as Pico
or one of the myriad GUI editors out there, but if you tend to make a habit out of the first thing that
you use, you don’t want to go down this route. 


                                                NOTE 
Editing text is where you’ll first start to see a difference between the terminal and the GUI. Editors 
such as vi run inside the terminal window, using the standard terminal I/O interface. GUI editors 
start their own window and present their own interface, independent of terminals. Emacs runs in a 
GUI by default but will run in a terminal wind



                                       Getting Online Help 
Linux systems come with a wealth of documentation. For basic commands, the manual pages (or man pages) 
will tell you what you need to know. For example, to see the manual page for the ls command, run man as follows:


                                               man ls 
Most manual pages concentrate primarily on reference information, perhaps with some examples and cross-
references, but that’s about it. Don’t expect a tutorial, and don’t expect an engaging literary style. 
When programs have many options, the manual page often lists the options in some systematic way
(for example, in alphabetical order), but it won’t tell you what the important ones are. If you’re patient,
you can usually find what you need to know in the man page. If you’re impatient, ask a friend—or pay someone
to be your friend so that you can ask him or her. 

To search for a manual page by keyword, use the -k option:


                                              man -k keyword 
This is helpful if you don’t quite know the name of the command that you want. For example, if you’re
looking for a command to sort something, run: 

$ man -k sort 
--snip-- 
comm (1)- compare two sorted files line by line qsort (3)- sorts an array sort (1)- sort lines of text files 
sortm (1)- sort messages 
tsort (1)- perform topological sort 

--snip-- 
The output includes the manual page name, the manual section (see below), and a quick description of what the
manual page contains.


                                                 NOTE 
If you have any questions about the commands described in the previous sections, you may be 
able to find the answers by using the man command. 

Manual pages are referenced by numbered sections. When someone refers to a manual page, the section number
appears in parentheses next to the name, like ping(8), for example. Table 2-3 lists the sections and their numbers.


                                    Section Description 

1 User commands 

2 System calls 

3 Higher-level Unix programming library documentation 

4 Device interface and driver information 

5 File descriptions (system configuration files) 

6 Games 

7 File formats, conventions, and encodings (ASCII, suffixes, and so on) 

8 System commands and servers


Sections 1, 5, 7, and 8 should be good supplements to this book. Section 4 may be of marginal use, and Section 
6 would be great if only it were a little larger. You probably won’t be able to use Section 3 if you aren’t a 
programmer, but you may be able to understand some of the material in Section 2 once you’ve read more 
about system calls in this book. 
You can select a manual page by section, which is sometimes important because man displays the first manual 
page that it finds when matching a particular search term. For example, to read the /etc/passwd file description 
(as opposed to the passwd command), you can insert the section number before the page name: 
$ man 5 passwd 
Manual pages cover the essentials, but there are many more ways to get online help. If you’re just looking for 
a certain option for a command, try entering a command name followed by --help or -h (the option varies 
from command to command). You may get a deluge (as in the case of ls --help), or you may find just 
what you’re looking for. 
Some time ago, the GNU Project decided that it didn’t like manual pages very much and switched to another 
format called info (or texinfo). Often this documentation goes further than a typical manual page does, but it 
is sometimes more complex. To access an info manual, use info with the command name: 

$ info command 

Some packages dump their available documentation into /usr/share/doc with no regard for online manual systems
such as man or info. See this directory on your system if you find yourself searching for documentation. And
of course, search the Internet.



                                               Shell Input and Output 
Now that you’re familiar with basic Unix commands, files, and directories, you’re ready to learn how to redirect
standard input and output. Let’s start with standard output. 

To send the output of command to a file instead of the terminal, use the > redirection character: 

$ command > file 

The shell creates file if it does not already exist. If file exists, the shell erases (clobbers) the original file 
first. (Some shells have parameters that prevent clobbering. For example, enter set -C to avoid clobbering in bash.) 

You can append the output to the file instead of overwriting it with the >> redirection syntax: 

$ command >> file 

This is a handy way to collect output in one place when executing sequences of related commands. 
To send the standard output of a command to the standard input of another command, use the pipe character 

(|). To see how this works, try these two commands: 

$ head /proc/cpuinfo 

$ head /proc/cpuinfo | tr a-z A-Z 

You can send output through as many piped commands as you wish; just add another pipe before each additional command.



                                                  Standard Error 
Occasionally, you may redirect standard output but find that the program still prints something to the terminal. 

This is called standard error (stderr); it’s an additional output stream for diagnostics and debugging. For example,
this command produces an error: 

$ ls /fffffffff > f 

After completion, f should be empty, but you still see the following error message on the terminal as standard error: 

ls: cannot access /fffffffff: No such file or directory 

You can redirect the standard error if you like. For example, to send standard output to f and standard error
to e, use the 2> syntax, like this: 

$ ls /fffffffff > f 2> e 

The number 2 specifies the stream ID that the shell modifies. Stream ID 1 is standard output (the default), and 2 is standard error. 
You can also send the standard error to the same place as stdout with the >& notation. For example, to send both standard
output and standard error to the file named f, try this command: 

$ ls /fffffffff > f 2>&1


                                                 Standard Input Redirection 
To channel a file to a program’s standard input, use the < operator: 

$ head < /proc/cpuinfo 

You will occasionally run into a program that requires this type of redirection, but because most Unix 
commands accept filenames as arguments, this isn’t very common. For example, the preceding command could have been
written as head /proc/cpuinfo. 

Understanding Error Messages When you encounter a problem on a Unix-like system such as Linux, you must read the error message.
Unlike messages from other operating systems, Unix errors usually tell you exactly what went wrong.



                                          Anatomy of a UNIX Error Message 
Most Unix programs generate and report the same basic error messages, but there can be subtle differences between
the output of any two programs. Here’s an example that you’ll certainly encounter in some form or other: 

$ ls /dsafsda 

ls: cannot access /dsafsda: No such file or directory There are three components to this message: 

o The program name, ls. Some programs omit this identifying information, which can be annoying when writing shell
scripts, but it’s not really a big deal. 

o The filename, /dsafsda, which is a more specific piece of information. There’s a problem with this path. 

o The error No such file or directory indicates the problem with the filename. 

Putting it all together, you get something like “ls tried to open /dsafsda but couldn’t because it doesn’t exist.”
This may seem obvious, but these messages can get a little confusing when you run a shell script that includes an erroneous
command under a different name. 

When troubleshooting errors, always address the first error first. Some programs report that they can’t do anything before
reporting a host of other problems. For example, say you run a fictitious program called scum and you see this error message: 

scumd: cannot access /etc/scumd/config: No such file or directory 
Following this is a huge list of other error messages that looks like a complete catastrophe. Don’t let those other
errors distract you. You probably just need to create /etc/scumd/config. 


                                                            NOTE 
Don’t confuse error messages with warning messages. Warnings often look like errors, but they 
contain the word warning. A warning usually means something is wrong but the program will try to 
continue running anyway. To fix a problem noted in a warning message, you may have to hunt 
down a process and kill it before doing anything else. (You’ll learn about listing and killing 
processes in 2.16 Listing and Manipulating Processes.)


                                                    Common Errors 
Many errors that you’ll encounter in Unix programs result from things that can go wrong with files and 
processes. Here’s an error message hit parade: 

No such file or directory
 
This is the number one error. You tried to access a file that doesn’t exist. Because the Unix file I/O system
doesn’t discriminate between files and directories, this error message occurs everywhere. You get it when you try to read
a file that does not exist, when you tryto change to a directory that isn’t there, when you try to write to a file
in a directory that doesn’t exist, and so on.



                                                                File exists 
In this case, you probably tried to create a file that already exists. This is common when you try to create a directory
with the same name as a file. 

Not a directory, Is a directory 
These messages pop up when you try to use a file as a directory or a directory as a file. For example: 

$ touch a 

$ touch a/b 

touch: a/b: Not a directory 
Notice that the error message only applies to the a part of a/b. When you encounter this problem, you may need to dig around
a little to find the path component that is being treated like a directory. No space left on device You’re out of disk space. 

Permission denied 

You get this error when you attempt to read or write to a file or directory that you’re not allowed to access 
(you have insufficient privileges). This error also shows when you try to execute a file that does not have the execute
bit set (even if you can read the file). You’ll read more about permissions in 2.17 File Modes and Permissions. 

Operation not permitted 
This usually happens when you try to kill a process that you don’t own. 

Segmentation fault, Bus error 
A segmentation fault essentially means that the person who wrote the program that you just ran screwed up somewhere.
The program tried to access a part of memory that it was not allowed to touch, and the operating system killed it.
Similarly, a bus error means that the program tried to access some memory in a particular way that it shouldn’t.
When you get one of these errors, you might be giving a program some input that it did not expect.


                                                Listing and Manipulating Processes 
Recall from Chapter 1 that a process is a running program. Each process on the system has a numeric process ID (PID).
For a quick listing of running processes, just run ps on the command line. You should get a list like this one: 

$ ps 
PID TTY STAT TIME COMMAND 
520 p0 S 0:00 -bash 
545 ? S 3:59 /usr/X11R6/bin/ctwm -W 
548 ? S 0:10 xclock -geometry -0-0 
2159 pd SW 0:00 /usr/bin/vi lib/addresses 
31956 p3 R 0:00 ps 

The fields are as follows: 
o PID. The process ID. 

o TTY. The terminal device where the process is running. More about this later. 

o STAT. The process status, that is, what the process is doing and where its memory resides. For example, S 
means sleeping and R means running. (See the ps(1) manual page for a description of all the symbols.) 

o TIME. The amount of CPU time in minutes and seconds that the process has used so far. In other words, 
the total amount of time that the process has spent running instructions on the processor. 

o COMMAND. This one might seem obvious, but be aware that a process can change this field from its original value.


                                                  Command Options 
The ps command has many options. To make things more confusing, you can specify options in three different 
styles—Unix, BSD, and GNU. Many people find the BSD style to be the most comfortable (perhaps because 
it involves less typing), so we’ll use the BSD style in this book. Here are some of the most useful option combinations: 

ps x Show all of your running processes. 

ps ax Show all processes on the system, not just the ones you own. 

ps u Include more detailed information on processes. 

ps w Show full command names, not just what fits on one line. 

As with other programs, you can combine options, as in ps aux and ps auxw. To check on a specific 
process, add its PID to the argument list of the ps command. For example, to inspect the current shell process, 
you could use ps u $$, because $$ is a shell variable that evaluates to the current shell’s PID. (You’ll find 
information on the administration commands top and lsof in Chapter 8. These can be useful for locating 
processes, even when doing something other than system maintenance.)



                                                         Killing Processes 
To terminate a process, send it a signal with the kill command. A signal is a message to a process from the kernel.
When you run kill, you’re asking the kernel to send a signal to another process. In most cases, all you need to do is this: 

$ kill pid 

There are many types of signals. The default is TERM, or terminate. You can send different signals by adding 
an extra option to kill. For example, to freeze a process instead of terminating it, use the STOP signal: 

$ kill -STOP pid 

A stopped process is still in memory, ready to pick up where it left off. Use the CONT signal to continue running the process again:

$ kill -CONT pid 

                                                          NOTE 
Using ctrl-c to terminate a process that is running in the current terminal is the same as using 
kill to end the process with the INT (interrupt) signal. 
The most brutal way to terminate a process is with the KILL signal. Other signals give the process a chance to
clean up after itself, but KILL does not. The operating system terminates the process and forcibly removes it from memory.
Use this as a last resort. 

You should not kill processes indiscriminately, especially if you don’t know what they’re doing. You may be shooting
yourself in the foot. 

You may see other users entering numbers instead of names with kill; for example, kill -9 instead of 
kill -KILL. This is because the kernel uses numbers to denote the different signals; you can use kill 
this way if you know the number of the signal that you want to send.


The kill command is used to send a signal to a process, which can be used to terminate, interrupt, or suspend the process. Here's how to use the kill command with signal numbers:

Signal Numbers
Here are some common signal numbers:

- 1 (SIGHUP): Hangup detected
- 2 (SIGINT): Interrupt from keyboard
- 3 (SIGQUIT): Quit from keyboard
- 9 (SIGKILL): Kill signal
- 11 (SIGSEGV): Invalid memory reference
- 15 (SIGTERM): Termination signal
- 18 (SIGCONT): Continue if stopped
- 19 (SIGSTOP): Stop process

Using the kill Command
To use the kill command, simply type kill followed by the signal number and the process ID (PID) of the process you want to send the signal to:


bash
kill -signal_number pid


For example, to send the SIGTERM signal (signal number 15) to a process with PID 1234:




                                                      Job Control 
Shells also support job control, which is a way to send TSTP (similar to STOP) and CONT signals to programs 
by using various keystrokes and commands. For example, you can send a TSTP signal with CTRL-Z, then start
the process again by entering fg (bring to foreground) or bg (move to background; see the next section). But 
despite its utility and the habits of many experienced users, job control is not necessary and can be confusing 
for beginners: It’s common for users to press CTRL-Z instead of CTRL-c, forget about what they were running, 
and eventually end up with numerous suspended processes hanging around. 

HINT 
To see if you’ve accidentally suspended any processes on your current terminal, run the jobs 
command. 
If you want to run multiple shells, run each program in a separate terminal window, put noninteractive 
processes in the background (as explained in the next section), or learn to use the screen program.


                                         Background Processes 
Normally, when you run a Unix command from the shell, you don’t get the shell prompt back until the program 
finishes executing. However, you can detach a process from the shell and put it in the “background” with the 
ampersand (&); this gives you the prompt back. For example, if you have a large file that you need to 
decompress with gunzip (you’ll see this in 2.18 Archiving and Compressing Files), and you want to do some 
other stuff while it’s running, run a command like this one: 

$ gunzip file.gz & 

The shell should respond by printing the PID of the new background process, and the prompt should return 
immediately so that you can continue working. The process will continue to run after you log out, which 
comes in particularly handy if you have to run a program that does a lot of number crunching for a while. 
(Depending on your setup, the shell might notify you when the process completes.) 
The dark side of running background processes is that they may expect to work with the standard input (or 
worse, read directly from the terminal). If a program tries to read something from the standard input when it’s 
in the background, it can freeze (try fg to bring it back) or terminate. Also, if the program writes to the 
standard output or standard error, the output can appear in the terminal window with no regard for anything 
else running there, meaning that you can get unexpected output when you’re working on something else. 
The best way to make sure that a background process doesn’t bother you is to redirect its output (and possibly 
input) as described in 2.14 Shell Input and Output. 

If spurious output from background processes gets in your way, learn how to redraw the content of your 
terminal window. The bash shell and most full-screen interactive programs support CTRL-L to redraw the entire screen.
If a program is reading from the standard input, CTRL-R usually redraws the current line, but pressing the wrong
sequence at the wrong time can leave you in an even worse situation than before. For example, entering CTRL-R at the
bash prompt puts you in reverse isearch mode (press ESC to exit).



                                          File Modes and Permissions 
Every Unix file has a set of permissions that determine whether you can read, write, or run the file.
Running ls -l displays the permissions. Here’s an example of such a display: 

-rw-r--r--➊ 1 juser somegroup 7041 Mar 26 19:34 endnotes.html 

The file’s mode ➊ represents the file’s permissions and some extra information. There are four parts to the mode,
as illustrated in Figure 2-1. 

The first character of the mode is the file type. A dash (-) in this position, as in the example, denotes a regular file,
meaning that there’s nothing special about the file. This is by far the most common kind of file.

Directories are also common and are indicated by a d in the file type slot. (3.1 Device Files lists the remaining file types.) 
Figure 2-1. The pieces of a file mode 
The rest of a file’s mode contains the permissions, which break down into three sets: user, group, and other,
in that order. For example, the rw- characters in the example are the user permissions, the r-- characters 
that follow are the group permissions, and the final r-- characters are the other permissions. 

Each permission set can contain four basic representations: 

r Means that the file is readable. 

w Means that the file is writable. 

x Means that the file is executable (you can run it as a program). - Means nothing. 

The user permissions (the first set) pertain to the user who owns the file. In the preceding example, that’s 
juser. The second set, group permissions, are for the file’s group (somegroup in the example). Any user in
that group can take advantage of these permissions. (Use the groups command to see what group you’re 
in, and see 7.3.5 Working with Groups for more information.) 
Everyone else on the system has access according to the third set, the other permissions, which are sometimes 
called world permissions. 

	user		group		others

	rwx		rwx		rwx
	-2-		4--		4-1

	rwx		rwx		rwx

	4-1		-21		42-
	5		3		6		

r = 4  -> 100 
w = 2  -> 010
x = 1  -> 001

                                                    NOTE 
Each read, write, and execute permission slot is sometimes called a permission bit. Therefore, you may hear
people refer to parts of the permissions as “the read bits.” 
Some executable files have an s in the user permissions listing instead of an x. This indicates that the 

executable is setuid, meaning that when you execute the program, it runs as though the file owner is the user
instead of you. Many programs use this setuid bit to run as root in order to get the privileges they need to change
system files. One example is the passwd program, which needs to change the /etc/passwd file.

                                                 Modifying Permissions 
To change permissions, use the chmod command. First, pick the set of permissions that you want to change, and then pick
the bit to change. For example, to add group (g) and world (o, for “other”) read (r) permissions to file, you could run
these two commands: 

$ chmod g+r file 

$ chmod o+r file 

Or you could do it all in one shot: 

$ chmod go+r file 

To remove these permissions, use go-r instead of go+r. 


                                                     NOTE 
Obviously, you shouldn’t make files world-writable because doing so gives anyone on your system 
the ability to change them. But would this allow anyone connected to the Internet to change your 
files? Probably not, unless your system has a network security hole. In that case, file permissions 
won’t help you anyway. 
You may sometimes see people changing permissions with numbers, for example: 


                                           $ chmod 644 file 
This is called an absolute change because it sets all permission bits at once. To understand how this works, 
you need to know how to represent the permission bits in octal form (each numeral represents a number in 
base 8 and corresponds to a permission set). See the chmod(1) manual page or info manual for more. 
You don’t really need to know how to construct absolute modes; just memorize the modes that you use most 
often. Table 2-4 lists the most common ones. 

Table 2-4. Absolute Permission Modes 
Mode Meaning Used For 

644 user: read/write; group, other: read files 

600 user: read/write; group, other: none files 

755 user: read/write/execute; group, other: read/execute directories, programs 

700 user: read/write/execute; group, other: none directories, programs 

711 user: read/write/execute; group, other: execute directories 
Directories also have permissions.

You can list the contents of a directory if it’s readable, but you can only access a file in a directory if the
directory is executable. (One common mistake people make when setting the permissions of directories is to accidentally
remove the execute permission when using absolute modes.) 

Finally, you can specify a set of default permissions with the umask shell command, which applies a 
predefined set of permissions to any new file you create. In general, use umask 022 if you want everyone to be able to see
all of the files and directories that you create, and use umask 077 if you don’t. (You’ll need 
to put the umask command with the desired mode in one of your startup files to make your new default permissions apply to
later sessions, as discussed in Chapter 13.)


                                                         Symbolic Links 
A symbolic link is a file that points to another file or a directory, effectively creating an alias (like a shortcut in Windows).
Symbolic links offer quick access to obscure a directory paths. 

In a long directory listing, symbolic links look like this (notice the l as the file type in the file mode):
 
lrwxrwxrwx 1 ruser users 11 Feb 27 13:52 somedir -> /home/origdir 

If you try to access somedir in this directory, the system gives you /home/origdir instead. Symbolic links are simply names
that point to other names. Their names and the paths to which they point don’t have to mean anything.
For example, /home/origdir doesn’t even need to exist. 
In fact, if /home/origdir does not exist, any program that accesses somedir reports that somedir doesn’t exist
(except for ls somedir, a command that stupidly informs you that somedir is somedir). This can be baffling because you
can see something named somedir right in front of your eyes. 

This is not the only way that symbolic links can be confusing. Another problem is that you can’t identify the
characteristics of a link target just by looking at the name of the link; you must follow the link to see if it goes to a
file or directory. Your system may also have links that point to other links, which are called chained symbolic links.


                                                 Creating Symbolic Links 
To create a symbolic link from target to linkname, use ln -s: 
$ ln -s target linkname 
The linkname argument is the name of the symbolic link, the target argument is the path of the file or directory that the
link points to, and the -s flag specifies a symbolic link (see the warning that follows). 
When making a symbolic link, check the command twice before you run it because several things can go wrong. For example,
if you reverse the order of the arguments (ln -s linkname target), you’re in for 
some fun if linkname is a directory that already exists. If this is the case (and it quite often is), ln creates a link named
target inside linkname, and the link will point to itself unless linkname is a full path. If something goes wrong when you
create a symbolic link to a directory, check that directory for errant symbolic links and remove them. 

Symbolic links can also cause headaches when you don’t know that they exist. For example, you can easily edit what you
think is a copy of a file but is actually a symbolic link to the original. 

                                                     WARNING 
Don’t forget the -s option when creating a symbolic link. Without it, ln creates a hard link, giving 
an additional real filename to a single file. The new filename has the status of the old one; it points 
(links) directly to the file data instead of to another filename as a symbolic link does. Hard links can 
be even more confusing than symbolic links. Unless you understand the material in 4.5 Inside a Traditional Filesystem,
avoid using them. 

With all of these warnings regarding symbolic links, why would anyone bother to use them? Because they offer a convenient
way to organize and share files, as well as patch up small problems.

                                         Archiving and Compressing Files 
Now that you’ve learned about files, permissions, and possible errors, you need to master gzip and tar. 


                                             gzip 
The program gzip (GNU Zip) is one of the current standard Unix compression programs. A file that ends with .gz is a
GNU Zip archive. Use gunzip file.gz to uncompress <file>.gz and remove the suffix; to 
compress it again, use gzip file.


                                              tar 
Unlike the zip programs for other operating systems, gzip does not create archives of files; that is, it doesn’t pack
multiple files and directories into one file. To create an archive, use tar instead: 

$ tar cvf archive.tar file1 file2 ... 

Archives created by tar usually have a .tar suffix (this is by convention; it isn’t required). For example, in the command
above, file1, file2, and so on are the names of the files and directories that you wish to archive in <archive>.tar.
The c flag activates create mode. The r and f flags have more specific roles. 

The v flag activates verbose diagnostic output, causing tar to print the names of the files and directories in the archive
when it encounters them. Adding another v causes tar to print details such as file size and permissions. If you don’t want
tar to tell you what it’s doing, omit the v flag. 

The f flag denotes the file option. The next argument on the command line after the f flag must be the archive file for tar
to create (in the preceding example, it is <archive>.tar). You must use this option followed by a filename at all times,
except with tape drives. To use standard input or output, enter a dash (-) instead of the filename.  

Unpacking tar files 


To unpack a .tar file with tar use the x flag: 

$ tar xvf archive.tar 

In this command, the x flag puts tar into extract (unpack) mode. You can extract individual parts of the 
archive by entering the names of the parts at the end of the command line, but you must know their exact names.
(To find out for sure, see the table-of-contents mode described shortly.)


                                                                     NOTE 
When using extract mode, remember that tar does not remove the archived .tar file after 
extracting its contents. 

Table-of-Contents Mode 
Before unpacking, it’s usually a good idea to check the contents of a .tar file with the table-of-contents mode by
using the t flag instead of the x flag. This mode verifies the archive’s basic integrity and prints the names of all
files inside. If you don’t test an archive before unpacking it, you can end up dumping a huge mess of files into the
current directory, which can be really difficult to clean up. 

When you check an archive with the t mode, verify that everything is in a rational directory structure; that is, 
all file pathnames in the archive should start with the same directory. If you’re unsure, create a temporary directory,
change to it, and then extract. (You can always use mv * .. if the archive didn’t create a mess.) 
When unpacking, consider using the p option to preserve permissions. Use this in extract mode to override your umask and
get the exact permissions specified in the archive. The p option is the default when working as the superuser.
If you’re having trouble with permissions and ownership when unpacking an archive as the superuser, make sure that you are
waiting until the command terminates and you get the shell prompt back. 

Although you may only want to extract a small part of an archive, tar must run through the whole thing, and you must not
interrupt the process because it sets the permissions only after checking the entire archive. 

Commit all of the tar options and modes in this section to memory. If you’re having trouble, make some 
flash cards. This may sound like grade-school, but it’s very important to avoid careless mistakes with this command.


                                              Compressed Archives (.tar.gz) 
Many beginners find it confusing that archives are normally found compressed, with filenames ending 
in .tar.gz. To unpack a compressed archive, work from the right side to the left; get rid of the .gz first and then worry
about the .tar. For example, these two commands decompress and unpack <file>.tar.gz: 

$ gunzip file.tar.gz 

$ tar xvf file.tar 

When starting out, you can do this one step at a time, first running gunzip to decompress and then tar to verify and unpack.
To create a compressed archive, do the reverse; run tar first and gzip second. Do this frequently enough, and you’ll soon
memorize how the archiving and compression process works. You’ll also get tired of all of the typing and start to look for
shortcuts. Let’s take a look at those now.


                                                             zcat 
The method shown above isn’t the fastest or most efficient way to invoke tar on a compressed archive, and it wastes
disk space and kernel I/O time. A better way is to combine archival and compression functions with 
a pipeline. For example, this command pipeline unpacks <file>.tar.gz: 

$ zcat file.tar.gz | tar xvf- 

The zcat command is the same as gunzip -dc. The -d option decompresses and the -c option sends the result to standard output
(in this case, to the tar command). 
Because it’s so common to use zcat, the version of tar that comes with Linux has a shortcut. You can use z as an option
to automatically invoke gzip on the archive; this works both for extracting an archive (with the x or t modes in tar) and
creating one (with c). For example, use the following to verify a compressed archive: 

$ tar ztvf file.tar.gz 

However, you should try to master the longer form before taking the shortcut. 

NOTE 
A .tgz file is the same as a .tar.gz file. The suffix is meant to fit into FAT (MS-DOS-based) filesystems.

Other Compression Utilities 

Another compression program in Unix is bzip2, whose compressed files end with .bz2. While marginally 
slower than gzip, bzip2 often compacts text files a little more, and it is therefore increasingly popular in the distribution
of source code. The decompressing program to use is bunzip2, and the options of both components are close enough to those
of gzip that you don’t need to learn anything new. The bzip2 
compression/decompression option for tar is j. 

A new compression program named xz is also gaining popularity. The corresponding decompression program is unxz, and the
arguments are similar to those of gzip. 

Most Linux distributions come with zip and unzip programs that are compatible with the zip archives on 
Windows systems. They work on the usual .zip files as well as self-extracting archives ending in .exe. But if you
encounter a file that ends in .Z, you have found a relic created by the compress program, which was once the Unix standard.
The gunzip program can unpack these files, but gzip won’t create them.

                                            Linux Directory Hierarchy Essentials 
Now that you know how to examine files, change directories, and read manual pages, you’re ready to start 
exploring your system files. The details of the Linux directory structure are outlined in the Filesystem 
Hierarchy Standard, or FHS (http://www.pathname.com/fhs/), but a brief walkthrough should suffice for now. 
Figure 2-2 offers a simplified overview of the hierarchy, showing some of the directories under /, /usr, and 
/var. Notice that the directory structure under /usr contains some of the same directory names as


                                       Here are the most important subdirectories in root: 

o /bin Contains ready-to-run programs (also known as an executables), including most of the basic Unix commands such
as ls and cp. Most of the programs in /bin are in binary format, having been created by a 
C compiler, but some are shell scripts in modern systems. 

o /dev Contains device files. You’ll learn more about these in Chapter 3. 

o /etc This core system configuration directory (pronounced EHT-see) contains the user password, boot, 
device, networking, and other setup files. Many items in /etc are specific to the machine’s hardware. For example,
the /etc/X11 directory contains graphics card and window system configurations. 

o /home Holds personal directories for regular users. Most Unix installations conform to this standard. 

o /lib An abbreviation for library, this directory holds library files containing code that executables can use.
There are two types of libraries: static and shared. The /lib directory should contain only shared libraries,
but other lib directories, such as /usr/lib, contain both varieties as well as other auxiliary files. (We’ll 
discuss shared libraries in more detail in Chapter 15.) 

o /proc Provides system statistics through a browsable directory-and-file interface. Much of the /proc subdirectory
structure on Linux is unique, but many other Unix variants have similar features. The /proc directory contains information
about currently running processes as well as some kernel parameters. 

o /sys This directory is similar to /proc in that it provides a device and system interface. You’ll read more 
about /sys in Chapter 3. 

o /sbin The place for system executables. Programs in /sbin directories relate to system management, so regular users
usually do not have /sbin components in their command paths. Many of the utilities found 
here will not work if you’re not running them as root.


/tmp A storage area for smaller, temporary files that you don’t care much about. Any user may read to and write from /tmp,
but the user may not have permission to access another user’s files there. Many programs use this directory as a workspace.
If something is extremely important, don’t put it in /tmp because most distributions clear /tmp when the machine boots and
some even remove its old files periodically. Also, don’t let /tmp fill up with garbage because its space is usually shared
with something critical (like the rest of /, for 
example). 

o /usr Although pronounced “user,” this subdirectory has no user files. Instead, it contains a large directory hierarchy,
including the bulk of the Linux system. Many of the directory names in /usr are the same as those in the root
directory (like /usr/bin and /usr/lib), and they hold the same type of files. (The reason that the root directory
does not contain the complete system is primarily historic—in the past, it was to keep space requirements low for the root.) 

o /var The variable subdirectory, where programs record runtime information. System logging, user tracking, caches, and other
files that system programs create and manage are here. (You’ll notice a /var/tmp directory here, but the system doesn’t
wipe it on boot.)

Other Root Subdirectories 

There are a few other interesting subdirectories in the root directory: 

o /boot Contains kernel boot loader files. These files pertain only to the very first stage of the Linux startup 
procedure; you won’t find information about how Linux starts up its services in this directory. See 
Chapter 5 for more about this. 

o /media A base attachment point for removable media such as flash drives that is found in many 
distributions. 

o /opt This may contain additional third-party software. Many systems don’t use /opt.


The /usr Directory 
The /usr directory may look relatively clean at first glance, but a quick look at /usr/bin and /usr/lib reveals 
that there’s a lot here; /usr is where most of the user-space programs and data reside. In addition to /usr/bin, 
/usr/sbin, and /usr/lib, /usr contains the following: 

o /include Holds header files used by the C compiler. 

o /info Contains GNU info manuals (see 2.13 Getting Online Help). 

o /local Is where administrators can install their own software. Its
 structure should look like that of / and /usr. 

o /man Contains manual pages. 

o /share Contains files that should work on other kinds of Unix machines with no loss of functionality. In the past,
networks of machines would share this directory, but a true /share directory is becoming rare because 
there are no space issues on modern disks. Maintaining a /share directory is often just a pain. In any case, /man, /info,
and some other subdirectories are often found here.


                                                            Kernel Location 
On Linux systems, the kernel is normally in /vmlinuz or /boot/vmlinuz. A boot loader loads this file into memory and
sets it in motion when the system boots. (You’ll find details on the boot loader in Chapter 5.) 
Once the boot loader runs and sets the kernel in motion, the main kernel file is no longer used by the running system.
However, you’ll find many modules that the kernel can load and unload on demand during the course of normal system operation.
Called loadable kernel modules, they are located under /lib/modules. 

                                                   Running Commands as the Superuser 
Before going any further, you should learn how to run commands as the superuser. You probably already know that you
can run the su command and enter the root password to start a root shell. This practice works, but it has certain disadvantages: 

o You have no record of system-altering commands. 

o You have no record of the users who performed system-altering commands. 

o You don’t have access to your normal shell environment. 

o You have to enter the root password.

                                                            sudo 
Most larger distributions use a package called sudo to allow administrators to run commands as root when they are logged
in as themselves. For example, in Chapter 7, you’ll learn about using vipw to edit the /etc/passwd file. You could do it like this: 

$ sudo vipw 

When you run this command, sudo logs this action with the syslog service under the local2 facility. You’ll also learn more
about system logs in Chapter 7.


                                                           /etc/sudoers 
Of course, the system doesn’t let just any user run commands as the superuser; you must configure the 
privileged users in your /etc/sudoers file. The sudo package has many options (that you’ll probably never use),
which makes the syntax in /etc/sudoers somewhat complicated. For example, this file gives user1 and user2 the power
to run any command as root without having to enter a password: 

User_Alias ADMINS = user1, user2 
ADMINS ALL = NOPASSWD: ALL 
root ALL=(ALL) ALL 

The first line defines an ADMINS user alias with the two users, and the second line grants the privileges. The 
ALL = NOPASSWD: ALL part means that the users in the ADMINS alias can use sudo to execute commands as root. The second
ALL means “any command.” The first ALL means “any host.” (If you have more than one machine, you can set different kinds
of access for each machine or group of machines, but we won’t cover 
that feature.) 

The root ALL=(ALL) ALL simply means that the superuser may also use sudo to run any command on 
any host. The extra (ALL) means that the superuser may also run commands as any other user. You can extend this privilege
to the ADMINS users by adding (ALL) to the /etc/sudoers line, as shown at ➊: 
ADMINS ALL = (ALL)➊ NOPASSWD: ALL 

                                                            NOTE 
Use the visudo command to edit /etc/sudoers. This command checks for file syntax errors after 
you save the file.

That’s it for sudo for now. If you need to use its more advanced features, see the sudoers(5) and sudo(8) 
manual pages. (The actual mechanics of user switching are covered in Chapter 7.)


                                           Looking Forward 
You should now know how to do the following at the command line: run programs, redirect output, interact with files
and directories, view process listings, view manual pages, and generally make your way around the user space of a Linux system.
You should also be able to run commands as the superuser. You may not yet 
know much about the internal details of user-space components or what goes on in the kernel, but with the basics of files
and processes under your belt, you’re on your way. In the next few chapters, you’ll be working 
with both kernel and user-space system components using the command-line tools that you just learned.



                                              Chapter 3. Devices 
This chapter is a basic tour of the kernel-provided device infrastructure in a functioning Linux system. 

Throughout the history of Linux, there have been many changes to how the kernel presents devices to the user. 

We’ll begin by looking at the traditional system of device files to see how the kernel provides device 
configuration information through sysfs. Our goal is to be able to extract information about the devices on a system
in order to understand a few rudimentary operations. Later chapters will cover interacting with specific kinds of
devices in greater detail. 

It’s important to understand how the kernel interacts with user space when presented with new devices. The udev system
enables user-space programs to automatically configure and use new devices.

You’ll see the basic workings of how the kernel sends a message to a user-space process through udev, as well as what
the process does with it. 


                                                       Device Files 
It is easy to manipulate most devices on a Unix system because the kernel presents many of the device I/O interfaces to
user processes as files. These device files are sometimes called device nodes. Not only can a programmer use regular file
operations to work with a device, but some devices are also accessible to standard programs like cat, so you don’t have to be
a programmer to use a device. However, there is a limit to what 
you can do with a file interface, so not all devices or device capabilities are accessible with standard file I/O. 

Linux uses the same design for device files as do other Unix flavors. Device files are in the /dev directory, and running
ls /dev reveals more than a few files in /dev. So how do you work with devices? 
To get started, consider this command: 

$ echo blah blah > /dev/null 

As does any command with redirected output, this sends some stuff from the standard output to a file. However,
the file is /dev/null, a device, and the kernel decides what to do with any data written to this device. In the case
of /dev/null, the kernel simply ignores the input and throws away the data. 

To identify a device and view its permissions, use ls -l: 
Example 3-1. Device files 

$ ls -l 

brw-rw---- 1 root disk 8, 1 Sep 6 08:37 sda1 

crw-rw-rw- 1 root root 1, 3 Sep 6 08:37 null 

prw-r--r-- 1 root root 0 Mar 3 19:17 fdata 

srw-rw-rw- 1 root root 0 Dec 18 07:43 log 

Note the first character of each line (the first character of the file’s mode) in Example 3-1. If this character is b, c, p, or s,
the file is a device. These letters stand for block, character, pipe, and socket, respectively, as described in more detail below. 


                                                Block device 
o Programs access data from a block device in fixed chunks. The sda1 in the preceding example is a disk device, a type
of block device. Disks can be easily split up into blocks of data. Because a block device’s 
total size is fixed and easy to index, processes have random access to any block in the device with the help 
of the kernel.


                                              Character device 
o Character devices work with data streams. You can only read characters from or write characters to character devices,
as previously demonstrated with /dev/null.

Character devices don’t have a size; when you read from or write to one, the kernel usually performs a read or write
operation on the device.

                                                    Printers 
directly attached to your computer are represented by character devices. It’s important to note that during character
device interaction, the kernel cannot back up and reexamine the data stream after it has passed data to a device or process. 

                                                Pipe device 
o Named pipes are like character devices, with another process at the other end of the I/O stream instead of a kernel driver. 

                                            Socket device 
o Sockets are special-purpose interfaces that are frequently used for interprocess communication. They’re often found outside
of the /dev directory. Socket files represent Unix domain sockets; you’ll learn more about those in Chapter 10. 

The numbers before the dates in the first two lines of Example 3-1 are the major and minor device numbers that help the kernel
identify the device. Similar devices usually have the same major number, such as sda3 and sdb1 (both of which are hard disk partitions). 


                                                   NOTE 
Not all devices have device files because the block and character device I/O interfaces are not 
appropriate in all cases. For example, network interfaces don’t have device files. It is theoretically 
possible to interact with a network interface using a single character device, but because it would 
be exceptionally difficult, the kernel uses other I/O interfaces.


                                        The sysfs Device Path 
The traditional Unix /dev directory is a convenient way for user processes to reference and interface with devices
supported by the kernel, but it’s also a very simplistic scheme. The name of the device in /dev tells you a little about the
device, but not a lot. Another problem is that the kernel assigns devices in the order in which they are found, so a device may
have a different name between reboots. 
To provide a uniform view for attached devices based on their actual hardware attributes, the Linux kernel offers the sysfs
interface through a system of files and directories. The base path for devices is /sys/devices. 

For example, the SATA hard disk at /dev/sda might have the following path in sysfs: 

/sys/devices/pci0000:00/0000:00:1f.2/host0/target0:0:0/0:0:0:0/block/s 
da 

As you can see, this path is quite long compared with the /dev/sda filename, which is also a directory. But you can’t really
compare the two paths because they have different purposes. The /dev file is there so that user processes can use the device,
whereas the /sys/devices path is used to view information and manage the device. 
If you list the contents of a device path such as the preceding one, you’ll see something like the following: 

alignment_offset 
discard_alignment holders 
removable size uevent 


bdi events 
inflight ro slaves 


capability events_async power sda1 stat 


dev events_poll_msecs queue sda2 
subsystem 


device ext_range range sda5 trace 


The files and subdirectories here are meant to be read primarily by programs rather than humans, but you can get an idea of
what they contain and represent by looking at an example such as the /dev file.

Running cat dev in this directory displays the numbers 8:0, which happen to be the major and minor device numbers of /dev/sda. 


There are a few shortcuts in the /sys directory. For example, /sys/block should contain all of the block devices available on a system.
However, those are just symbolic links; run ls -l /sys/block to reveal the true sysfs paths. 

It can be difficult to find the sysfs location of a device in /dev. Use the udevadm command to show the path and other attributes: 

$ udevadm info --query=all --name=/dev/sda 

                                                 NOTE 
The udevadm program is in /sbin; you can put this directory at the end of your path if it’s not already there. 

You’ll find more details about udevadm and the entire udev system in 3.5 udev.


                                                  dd and Devices 
The program dd is extremely useful when working with block and character devices. This program’s sole function is to read from
an input file or stream and write to an output file or stream, possibly doing some 
encoding conversion on the way. 
dd copies data in blocks of a fixed size. Here’s how to use dd with a character device and some common options: 

$ dd if=/dev/zero of=new_file bs=1024 count=1 

As you can see, the dd option format differs from the option formats of most other Unix commands; it’s based 
on an old IBM Job Control Language (JCL) style. Rather than use the dash (-) character to signal an option, you name an option
and set its value to something with the equals (=) sign. The preceding example copies a single 1024-byte block
from /dev/zero (a continuous stream of zero bytes) to new_file. 

These are the important dd options: 
o if=file The input file. The default is the standard input. 


o of=file The output file. The default is the standard output. 


o bs=size The block size. dd reads and writes this many bytes of data at a time. To abbreviate large chunks of data,
you can use b and k to signify 512 and 1024 bytes, respectively. Therefore, the example above could read bs=1k instead of bs=1024.

o ibs=size, obs=size The input and output block sizes. If you can use the same block size for both 
input and output, use the bs option; if not, use ibs and obs for input and output, respectively. 

o count=num The total number of blocks to copy. When working with a huge file—or with a device that 
supplies an endless stream of data, such as /dev/zero—you want dd to stop at a fixed point or you could 
waste a lot of disk space, CPU time, or both. Use count with the skip parameter to copy a small piece 
from a large file or device. 

o skip= o num Skip past the first num blocks in the input file or stream and do not copy them to the output. 

                                                   WARNING 
dd is very powerful, so make sure you know what you’re doing when you run it. It’s very easy to corrupt files and data
on devices by making a careless mistake. It often helps to write the output to a new file if you’re not sure what it will do.



                                               Device Name Summary 
It can sometimes be difficult to find the name of a device (for example, when partitioning a disk). Here are a few ways to
find out what it is: 
o Query udevd using udevadm (see 3.5 udev). 

o Look for the device in the /sys directory. 

o Guess the name from the output of the dmesg command (which prints the last few kernel messages) or the kernel system log file
(see 7.2 System Logging). This output might contain a description of the devices on your system. 

o For a disk device that is already visible to the system, you can check the output of the mount command. 

o Run cat /proc/devices to see the block and character devices for which your system currently has 
drivers. Each line consists of a number and name. The number is the major number of the device as 
described in 3.1 Device Files. If you can guess the device from the name, look in /dev for the character or block devices
with the corresponding major number, and you’ve found the device files. 

Among these methods, only the first is reliable, but it does require udev. If you get into a situation where udev is not available,
try the other methods but keep in mind that the kernel might not have a device file for your hardware. 

The following sections list the most common Linux devices and their naming conventions.


                                           
                                                   Hard Disks: /dev/sd* 
Most hard disks attached to current Linux systems correspond to device names with an sd prefix, such as 
/dev/sda, /dev/sdb, and so on. These devices represent entire disks; the kernel makes separate device files, such as
/dev/sda1 and /dev/sda2, for the partitions on a disk. 

The naming convention requires a little explanation. The sd portion of the name stands for SCSI disk.

Small Computer System Interface (SCSI) was originally developed as a hardware and protocol standard for 
communication between devices such as disks and other peripherals. Although traditional SCSI hardware isn’t used in most
modern machines, the SCSI protocol is everywhere due to its adaptability. For example, USB 
storage devices use it to communicate. The story on SATA disks is a little more complicated, but the Linux kernel still uses
SCSI commands at a certain point when talking to them. 

To list the SCSI devices on your system, use a utility that walks the device paths provided by sysfs. One of the most
succinct tools is lsscsi. Here is what you can expect when you run it: 

$ lsscsi 
[0:0:0:0]➊ disk➋ ATA WDC WD3200AAJS-2 01.0 /dev/sda➌ 
[1:0:0:0] cd/dvd Slimtype DVD A DS8A5SH XA15 /dev/sr0 
[2:0:0:0] disk FLASH Drive UT_USB20 0.00 /dev/sdb 

The first column ➊ identifies the address of the device on the system, the second ➋ describes what kind of device it is, and
the last ➌ indicates where to find the device file. Everything else is vendor information. 


Linux assigns devices to device files in the order in which its drivers encounter devices. So in the previous example,
the kernel found the disk first, the optical drive second, and the flash drive last. 

Unfortunately, this device assignment scheme has traditionally caused problems when reconfiguring hardware. 

Say, for example, that you have a system with three disks: /dev/sda, /dev/sdb, and /dev/sdc. If /dev/sdb explodes and you must
remove the disk so that the machine can work again, the former /dev/sdc moves to /dev/sdb, and there is no longer a /dev/sdc.
If you were referring to the device names directly in the fstab file (see 4.2.8 The /etc/fstab Filesystem Table), you’d have
to make some changes to that file in order to get things (mostly) back to normal. To solve this problem, most modern Linux systems
use the Universally Unique Identifier (UUID, see 4.2.4 Filesystem UUID) for persistent disk device access. 

This discussion has barely scratched the surface of how to use disks and other storage devices on Linux systems. See Chapter 4
for more information about using disks. Later in this chapter, we’ll examine how SCSI support works in the Linux kernel.


3.4.2 CD and DVD Drives: /dev/sr* 

Linux recognizes most optical storage drives as the SCSI devices /dev/sr0, /dev/sr1, and so on.

However, if the drive uses an older interface, it might show up as a PATA device, as discussed below. The /dev/sr* devices are
read only, and they are used only for reading from discs. For the write and rewrite capabilities of optical 
devices, you’ll use the “generic” SCSI devices such as /dev/sg0. 


3.4.3 PATA Hard Disks: /dev/hd* 
The Linux block devices /dev/hda, /dev/hdb, /dev/hdc, and /dev/hdd are common on older versions of the Linux kernel and with
older hardware. These are fixed assignments based on the master and slave devices on 
interfaces 0 and 1. At times, you might find a SATA drive recognized as one of these disks. This means that the SATA drive is
running in a compatibility mode, which hinders performance. Check your BIOS settings to see if you can switch the SATA controller
to its native mode. 


3.4.4 Terminals: /dev/tty*, /dev/pts/*, and /dev/tty 

Terminals are devices for moving characters between a user process and an I/O device, usually for text output to a terminal screen.
The terminal device interface goes back a long way, to the days when terminals were typewriter-based devices. 

Pseudoterminal devices are emulated terminals that understand the I/O features of real terminals. But rather than talk to
a real piece of hardware, the kernel presents the I/O interface to a piece of software, such as the shell terminal window that
you probably type most of your commands into. 

Two common terminal devices are /dev/tty1 (the first virtual console) and /dev/pts/0 (the first pseudoterminal device).
The /dev/pts directory itself is a dedicated filesystem. 


The /dev/tty device is the controlling terminal of the current process. If a program is currently reading from and writing to
a terminal, this device is a synonym for that terminal. A process does not need to be attached to a terminal.



                                         Display Modes and Virtual Consoles 
Linux has two primary display modes: text mode and an X Window System server (graphics mode, usually via a display manager).
Although Linux systems traditionally booted in text mode, most distributions now use 
kernel parameters and interim graphical display mechanisms (bootsplashes such as plymouth) to completely hide text mode as
the system is booting. In such cases, the system switches over to full graphics mode near the end of the boot process. 
Linux supports virtual consoles to multiplex the display. Each virtual console may run in graphics or text 
mode. When in text mode, you can switch between consoles with an ALT-Function key combination—for 
example, ALT-F1 takes you to /dev/tty1, ALT-F2 goes to /dev/tty2, and so on. Many of these may be occupied by a getty process
running a login prompt, as described in 7.4 getty and login. 

A virtual console used by the X server in graphics mode is slightly different. Rather than getting a virtual console assignment
from the init configuration, an X server takes over a free virtual console unless directed to use a specific virtual console.
For example, if you have getty processes running on tty1 and tty2, a new X server takes over tty3. In addition, after
the X server puts a virtual console into graphics mode, you must normally press a CTRL-ALT-Function key combination to switch
to another virtual console instead of the simpler ALT-Function key combination. 

The upshot of all of this is that if you want to see your text console after your system boots, press CTRL-ALT- F1. To
return to the X11 session, press ALT-F2, ALT-F3, and so on, until you get to the X session. 

If you run into trouble switching consoles due to a malfunctioning input mechanism or some other 


circumstance, you can try to force the system to change consoles with the chvt command. For example, to 
switch to tty1, run the following as root: 

# chvt 1



3.4.5 Serial Ports: /dev/ttyS* 

Older RS-232 type and similar serial ports are special terminal devices. You can’t do much on the command 
line with serial port devices because there are too many settings to worry about, such as baud rate and flow control. 

The port known as COM1 on Windows is /dev/ttyS0; COM2 is /dev/ttyS1; and so on. Plug-in USB serial adapters show up with USB
and ACM with the names /dev/ttyUSB0, /dev/ttyACM0, /dev/ttyUSB1, /dev/ttyACM1, and so on. 


3.4.6 Parallel Ports: /dev/lp0 and /dev/lp1 

Representing an interface type that has largely been replaced by USB, the unidirectional parallel port devices /dev/lp0 and
/dev/lp1 correspond to LPT1: and LPT2: in Windows. You can send files (such as a file to be printed) directly to a parallel port
with the cat command, but you might need to give the printer an extra form feed or reset afterward. A print server such as CUPS is
much better at handling interaction with a printer. 

The bidirectional parallel ports are /dev/parport0 and /dev/parport1.

 
3.4.7 Audio Devices: /dev/snd/*, /dev/dsp, /dev/audio, and More 
Linux has two sets of audio devices. There are separate devices for the Advanced Linux Sound Architecture (ALSA) system interface
and the older Open Sound System (OSS). The ALSA devices are in the /dev/snd directory, but it’s difficult to work with them
directly. Linux systems that use ALSA support OSS backward- compatible devices if the OSS kernel support is currently loaded. 

Some rudimentary operations are possible with the OSS dsp and audio devices. For example, the computer plays any WAV file that
you send to /dev/dsp. However, the hardware may not do what you expect due to frequency mismatches.

Furthermore, on most systems, the device is often busy as soon as you log in. 

                                              
                                                             NOTE 
Linux sound is a messy subject due to the many layers involved. We’ve just talked about the kernel-level devices, but typically
there are user-space servers such as pulse-audio that manage audio from different sources and act as intermediaries between the
sound devices and other user- space processes.



                                                        Creating Device Files 
In modern Linux systems, you do not create your own device files; this is done with devtmpfs and udev (see 3.5 udev). However,
it is instructive to see how it was once done, and on a rare occasion, you might need to create a named pipe. 

The mknod command creates one device. You must know the device name as well as its major and minor numbers. For example,
creating /dev/sda1 is a matter of using the following command: 

# mknod /dev/sda1 b 8 2 

The b 8 2 specifies a block device with a major number 8 and a minor number 2. For character or named 
pipe devices, use c or p instead of b (omit the major and minor numbers for named pipes). 

As mentioned earlier, the mknod command is useful only for creating the occasional named pipe. At one time, it was also
sometimes useful for creating missing devices in single-user mode during system recovery. 

In older versions of Unix and Linux, maintaining the /dev directory was a challenge. With every significant 
kernel upgrade or driver addition, the kernel could support more kinds of devices, meaning that there would be a new set of
major and minor numbers to be assigned to device filenames. Maintaining this was difficult, so each system had a MAKEDEV program
in /dev to create groups of devices. When you upgraded your system, you would try to find an update to MAKEDEV and then run
it in order to create new devices. 

This static system became ungainly, so a replacement was in order. The first attempt to fix it was devfs, a kernel-space
implementation of /dev that contained all of the devices that the current kernel supported. 
However, there were a number of limitations, which led to the development of udev and devtmpfs.
 
3.5 udev 
We’ve already talked about how unnecessary complexity in the kernel is dangerous because you can too easily introduce system
instability. Device file management is an example: You can create device files in user space, so why would you do this
in the kernel? The Linux kernel can send notifications to a user-space process (called udevd) upon detecting a new device
on the system (for example, when someone attaches a USB flash drive). 

The user-space process on the other end examines the new device’s characteristics, creates a device file, and then
performs any device initialization. 

That was the theory. Unfortunately, in practice, there is a problem with this approach—device files are 
necessary early in the boot procedure, so udevd must start early. To create device files, udevd could not depend on
any devices that it was supposed to create, and it would need to perform its initial startup very quickly so that the
rest of the system wouldn’t get held up waiting for udevd to start. 



3.5.1 devtmpfs 

The devtmpfs filesystem was developed in response to the problem of device availability during boot (see 4.2 Filesystems for
more details on filesystems). This filesystem is similar to the older devfs support, but it’s simplified. The kernel
creates device files as necessary, but it also notifies udevd that a new device is available. Upon receiving this signal,
udevd does not create the device files, but it does perform device initialization and process notification. Additionally,
it creates a number of symbolic links in /dev to further identify devices. You can find examples in the directory
/dev/disk/by-id, where each attached disk has one or more entries. 

For example, consider this typical disk: 

lrwxrwxrwx 1 root root 9 Jul 26 10:23 scsi-SATA_WDC_WD3200AAJS-_WD- WMAV2FU80671 -> ../../sda 

lrwxrwxrwx 1 root root 10 Jul 26 10:23 scsi-SATA_WDC_WD3200AAJS-_WD- WMAV2FU80671-part1 -> ../../sda1 

lrwxrwxrwx 1 root root 10 Jul 26 10:23 scsi-SATA_WDC_WD3200AAJS-_WD- WMAV2FU80671-part2 -> ../../sda2 

lrwxrwxrwx 1 root root 10 Jul 26 10:23 scsi-SATA_WDC_WD3200AAJS-_WD- WMAV2FU80671-part5 -> ../../sda5 

udevd names the links by interface type, and then by manufacturer and model information, serial number, 
and partition (if applicable). 

But how does udevd know which symbolic links to create, and how does it create them? The next section describes how udevd
does its work. However, you don’t need to know that to continue on with the book. In fact, if this is your first time looking
at Linux devices, you’re encouraged to move to the next chapter to start 
learning about how to use disks.



3.5.2 udevd Operation and Configuration 

The udevd daemon operates as follows: 

1. The kernel sends udevd a notification event, called a uevent, through an internal network link. 

2. udevd loads all of the attributes in the uevent.

3. udevd parses its rules, and it takes actions or sets more attributes based on those rules. 
An incoming uevent that udevd receives from the kernel might look like this: 

ACTION=change 
DEVNAME=sde 
DEVPATH=/devices/pci0000:00/0000:00:1a.0/usb1/1-1/1-1.2/1- 
1.2:1.0/host4/ 
target4:0:0/4:0:0:3/block/sde 
DEVTYPE=disk 
DISK_MEDIA_CHANGE=1 
MAJOR=8 
MINOR=64 
SEQNUM=2752 
SUBSYSTEM=block 
UDEV_LOG=3 

You can see here that there is a change to a device. After receiving the uevent, udevd knows the sysfs device path and a
number of other attributes associated with the properties, and it is now ready to start processing rules. 


The rules files are in the /lib/udev/rules.d and /etc/udev/rules.d directories. The rules in /lib are the defaults, and
the rules in /etc are overrides. A full explanation of the rules would be tedious, and you can learn much more from the
udev(7) manual page, but let’s look at the symbolic
ATTRS{type}=="5", ATTRS{scsi_level}=="[6-9]*", 
IMPORT{program}="ata_id --export $tempnode" 

These rules match ATA disks presented through the kernel’s SCSI subsystem (see 3.6 In-Depth: SCSI and the Linux Kernel).
You can see that there are a few rules to catch different ways that the devices may be represented, but the idea is that
udevd will try to match a device starting with sd or sr but without a number (with the KERNEL=="sd*[!0-9]|sr*" expression),
as well as a subsystem (SUBSYSTEMS=="scsi"), 
and finally, some other attributes. If all of those conditional expressions are true, udevd moves to the next 
expression:


IMPORT{program}="ata_id --export $tempnode" 

This is not a conditional, but rather, a directive to import variables from the /lib/udev/ata_id command. If you have such
a disk, try it yourself on the command line: 

$ sudo /lib/udev/ata_id --export /dev/sda 
ID_ATA=1 
ID_TYPE=disk 
ID_BUS=ata 
ID_MODEL=WDC_WD3200AAJS-22L7A0 
ID_MODEL_ENC=WDC\x20WD3200AAJS22L7A0\x20\x20\x20\x20\x20\x20\x20\x20\x 
20\x20 
\x20\x20\x20\x20\x20\x20\x20\x20\x20 
ID_REVISION=01.03E10 
ID_SERIAL=WDC_WD3200AAJS-22L7A0_WD-WMAV2FU80671 

--snip-- 

The import now sets the environment so that all of the variable names in this output are set to the values shown. 
For example, any rule that follows will now recognize ENV{ID_TYPE} as disk. 

Of particular note is ID_SERIAL. In each of the rules, this conditional appears second: 

ENV{ID_SERIAL}!="?*" 

This means that ID_SERIAL is true only if is not set. Therefore, if it is set, the conditional is false, the entire current
rule is false, and udevd moves to the next rule. 

So what’s the point? The object of the object of these two rules (and many around them in the file) is to find the serial 
number of the disk device. With ENV{ID_SERIAL} set, udevd can now evaluate this rule: 

KERNEL=="sd*|sr*|cciss*", ENV{DEVTYPE}=="disk", ENV{ID_SERIAL}=="?*", 
SYMLINK+="disk/by-id/$env{ID_BUS}-$env{ID_SERIAL}" 

You can see that this rule requires ENV{ID_SERIAL} to be set, and it has one directive: 

SYMLINK+="disk/by-id/$env{ID_BUS}-$env{ID_SERIAL}" 

Upon encountering this directive, udevd adds a symbolic link for the incoming device. So now you know 
where the device symbolic links came from! 
You may be wondering how to tell a conditional expression from a directive. Conditionals are denoted by two
equal signs (==) or a bang equal (!=), and directives by a single equal sign (=), a plus equal (+=), or a colon equal (:=).



3.5.3 udevadm 

The udevadm program is an administration tool for udevd. You can reload udevd rules and trigger events, but perhaps the
most powerful features of udevadm are the ability to search for and explore system devices and the ability to monitor uevents
as udevd receives them from the kernel. The only trick is that the command syntax can get a bit involved. 

Let’s start by examining a system device. Returning to the example in 3.5.2 udevd Operation and 
Configuration, in order to look at all of the udev attributes used and generated in conjunction with the rules for
a device such as /dev/sda, run the following command: 

$ udevadm info --query=all –-name=/dev/sda 

The output looks like this: 

P: 
/devices/pci0000:00/0000:00:1f.2/host0/target0:0:0/0:0:0:0/block/sda 
N: sda 
S: disk/by-id/ata-WDC_WD3200AAJS-22L7A0_WD-WMAV2FU80671 
S: disk/by-id/scsi-SATA_WDC_WD3200AAJS-_WD-WMAV2FU80671 
S: disk/by-id/wwn-0x50014ee057faef84 S: disk/by-path/pci-0000:00:1f.2- 
scsi-0:0:0:0 
E: DEVLINKS=/dev/disk/by-id/ata-WDC_WD3200AAJS-22L7A0_WD-WMAV2FU80671 
/dev/disk/by-id/scsi 
-SATA_WDC_WD3200AAJS-_WD-WMAV2FU80671 /dev/disk/by-id/wwn- 
0x50014ee057faef84 /dev/disk/by 
-path/pci-0000:00:1f.2-scsi-0:0:0:0 
E: DEVNAME=/dev/sda 
E: 
DEVPATH=/devices/pci0000:00/0000:00:1f.2/host0/target0:0:0/0:0:0:0/blo 
ck/sda 
E: DEVTYPE=disk 
E: ID_ATA=1 
E: ID_ATA_DOWNLOAD_MICROCODE=1 
E: ID_ATA_FEATURE_SET_AAM=1 
--snip-- 

The prefix in each line indicates an attribute or other characteristic of the device. In this case, the P: at the 
top is the sysfs device path, the N: is the device node (that is, the name given to the /dev file), S: indicates a 
symbolic link to the device node that udevd placed in /dev according to its rules, and E: is additional device information
extracted in the udevd rules. (There was far more output in this example than was necessary to show here; try the command for
yourself to get a feel for what it does.)



3.5.4 Monitoring Devices 

To monitor uevents with udevadm, use the monitor command: 

$ udevadm monitor 

Output (for example, when you insert a flash media device) looks like this abbreviated sample: 
KERNEL[658299.569485] add /devices/pci0000:00/0000:00:1d.0/usb2/2- 
1/2-1.2 (usb) 
KERNEL[658299.569667] add /devices/pci0000:00/0000:00:1d.0/usb2/2- 
1/2-1.2/2-1.2:1.0 (usb) 
KERNEL[658299.570614] add /devices/pci0000:00/0000:00:1d.0/usb2/2- 
1/2-1.2/2-1.2:1.0/host15 
(scsi) 
KERNEL[658299.570645] add /devices/pci0000:00/0000:00:1d.0/usb2/2- 
1/2-1.2/2-1.2:1.0/ 
host15/scsi_host/host15 (scsi_host) 
UDEV [658299.622579] add /devices/pci0000:00/0000:00:1d.0/usb2/2- 
1/2-1.2 (usb) 
UDEV [658299.623014] add /devices/pci0000:00/0000:00:1d.0/usb2/2- 
1/2-1.2/2-1.2:1.0 (usb) 
UDEV [658299.623673] add /devices/pci0000:00/0000:00:1d.0/usb2/2- 
1/2-1.2/2-1.2:1.0/host15 
(scsi) www.EBooksWorld.ir 
UDEV [658299.623690] add /devices/pci0000:00/0000:00:1d.0/usb2/2- 
1/2-1.2/2-1.2:1.0/ 
host15/scsi_host/host15 (scsi_host) 
--snip-- 


There are two copies of each message in this output because the default behavior is to print both the incoming message from
the kernel (marked with KERNEL) and the message


Getting Started with tmux

tmux (Terminal Multiplexer) allows you to create, manage, and switch between multiple terminal sessions in a single window.

1. Install tmux

Most Linux distributions have tmux in their package manager:

# Debian/Ubuntu
sudo apt install tmux

. Start a New tmux Session

2. tmux

or start with a specific name:

tmux new -s mysession

3. Basic Commands

Once inside tmux, use the prefix key (Ctrl+b) followed by a command.

4. Managing Sessions

To list active sessions:

tmux ls

To reattach to a session:

tmux attach -t mysession

To kill a session:

tmux kill-session -t mysession

Tmux cheat sheet

tmux sessions

_NEW SESSION

tmux

tmux new

tmux new-session

tmux new -s sessionname


_ ATTACH SESSION

tmux a
tmux att
tmux attach
tmux attach-session
tmux a -t sessionname

_ REMOVE SESSION

tmux kill-ses
tmux kill-session -t sessionname

_ KEY BINDING

CTRL + B $   	rename session
CTRL + B D	  detach session
CTRL + B )	    next session
CTRL + B (	    previous session


tmux windows

_ windows are like tabs in a browser. 

Windows exist in sessions and occupy the space of a session screen.


key bindings	
CTRL + B C	      create window

CTRL + B N	      move to next window

CTRL + B P       	move to previous window

CTRL + B L	      move to window last used

CTRL + B 0 … 9	      select window '

CTRL + B &	        kill window

CTRL + B W      	list windows

tmux panes
_ panes are sections of windows that have been split into different screens — just like the panes of a real window!

key bindings	
CTRL + B %	vertical split
CTRL + B “	horizontal split
CTRL + B →	move to pane to the right
CTRL + B ←	move to pane to the left
CTRL + B ↑	move up to pane
CTRL + B ↓	move down to pane
CTRL + B O	go to next pane
CTRL + B ;	go to last active pane
CTRL + B }	move pane right
CTRL + B {	move pane left
CTRL + B !	convent pane to window
CTRL + B X	kill pane

tmux copy mode

_ key bindings	
CTRL + B [	enter copy mode
CTRL + B ]	paste from buffer

_ copy mode commands	
space	start selection
enter	copy selection
esc	clear selection
g	go to top
G	go to bottom
h	move cursor left
j	move cursor down
k	move cursor up
l	move cursor right
/	search
#	list paste buffers
q	quit



that udevd sends out to other programs when it’s finished processing and filtering the event. To see only kernel events, add
the --kernel option, and to see only outgoing events, use --udev. To see the whole incoming uevent, including the attributes as
shown in 3.5.2 udevd Operation and Configuration, use the --property option

You can also filter events by subsystem. For example, to see only kernel messages pertaining to changes in the SCSI subsystem, use this command:

udevadm monitor --kernel --subsystem-match=scsi 

For more on udevadm, see the udevadm(8) manual page. 
There’s much more to udev. For example, the D-Bus system for interprocess communication has a daemon called udisks-daemon that listens
to the outgoing udevd events in order to automatically attach disks and to further notify other desktop software that a new disk
is now available.

In-Depth: SCSI and the Linux Kernel 

In this section, we’ll take a look at the SCSI support in the Linux kernel as a way to explore part of the Linux 
kernel architecture. You don’t need to know any of this information in order to use disks, so if you’re in a 
hurry to use one, move on to Chapter 4. In addition, the material here is more advanced and theoretical in nature that what you’ve
seen so far, so if you want to stay hands-on, you should definitely skip to the next chapter. 

Let’s begin with a little background. The traditional SCSI hardware setup is a host adapter linked with a chain of devices over an
SCSI bus, as shown in Figure 3-1. The host adapter is attached to a computer.

The host adapter and devices each have an SCSI ID, and there can be 8 or 16 IDs per bus, depending on the SCSI 
version. You might hear the term SCSI target used to refer to a device and its SCSI ID.

The host adapter communicates with the devices through the SCSI command set in a peer-to-peer relationship; the devices send responses
back to the host adapter. The computer is not directly attached to the device chain, so it must go through the host adapter in order
to communicate with disks and other devices. Typically, the computer sends SCSI commands to the host adapter to relay to the devices,
and the devices relay responses back through the host adapter. 

Newer versions of SCSI, such as Serial Attached SCSI (SAS), offer exceptional performance, but you probably won’t find true SCSI devices
in most machines. You’ll more often encounter USB storage devices that use

SCSI commands. In addition, devices supporting ATAPI (such as CD/DVD-ROM drives) use a version of the SCSI command set. 

SATA disks also appear on your system as SCSI devices by means of a translation layer in libata (
SCSI and ATA). Some SATA controllers (especially high-performance RAID controllers) perform this translation in hardware. 

How does this all fit together? Consider the devices shown on the following system:

lsscsi 

[0:0:0:0] disk ATA WDC WD3200AAJS-2 01.0 /dev/sda 
[1:0:0:0] cd/dvd Slimtype DVD A DS8A5SH XA15 /dev/sr0 
[2:0:0:0] disk USB2.0 CardReader CF 0100 /dev/sdb 
[2:0:0:1] disk USB2.0 CardReader SM XD 0100 /dev/sdc 
[2:0:0:2] disk USB2.0 CardReader MS 0100 /dev/sdd 
[2:0:0:3] disk USB2.0 CardReader SD 0100 /dev/sde 
[3:0:0:0] disk FLASH Drive UT_USB20 0.00 /dev/sdf 

The numbers in brackets are, from left to right, the SCSI host adapter number, the SCSI bus number, the device SCSI ID, and the LUN
(logical unit number, a further subdivision of a device). In this example, there are four attached adapters (scsi0, scsi1, scsi2, and scsi3),
each of which has a single bus (all with bus number 0), and just one device on each bus (all with target 0). The USB card reader at
2:0:0 has four logical units, though— one for each kind of flash card that can be inserted. The kernel has assigned a different
device file to each logical unit. 

Figure 3-2 illustrates the driver and interface hierarchy inside the kernel for this particular system 
configuration, from the individual device drivers up to the block drivers. It does not include the SCSI generic (sg) drivers.


Although this is a large structure and may look overwhelming at first, the data flow in the figure is very linear. 

Let’s begin dissecting it by looking at the SCSI subsystem and its three layers of drivers: 

1) The top layer handles operations for a class of device. For example, the sd (SCSI disk) driver is at this 
layer; it knows how to translate requests from the kernel block device interface into disk-specific 
commands in the SCSI protocol, and vice versa. 

2) The middle layer moderates and routes the SCSI messages between the top and bottom layers, and keeps track of all of the SCSI buses and
devices attached to the system. 

3) The bottom layer handles hardware-specific actions. The drivers here send outgoing SCSI protocol messages to specific host adapters or
hardware, and they extract incoming messages from the hardware. 

The reason for this separation from the top layer is that although SCSI messages are uniform for a device 
class (such as the disk class), different kinds of host adapters have varying procedures for sending the same messages. 

The top and bottom layers contain many different drivers, but it’s important to remember that, for any given device file on your system,
the kernel uses one top-layer driver and one lower-layer driver. For the disk at /dev/sda in our example, the kernel uses the sd top-layer
driver and the ATA bridge lower-layer driver. 
There are times when you might use more than one upper-layer driver for one hardware device (see 3.6.3 Generic SCSI Devices). For
true hardware SCSI devices, such as a disk attached to an SCSI host adapter or a hardware RAID controller, the lower-layer drivers
talk directly to the hardware below. However, for most hardware that you find attached to the SCSI subsystem, it’s a different story.


                                                 USB Storage and SCSI 
In order for the SCSI subsystem to talk to common USB storage hardware, as shown in Figure 3-2, the kernel needs more than just a
lower-layer SCSI driver. The USB flash drive represented by /dev/sdf understands SCSI 
commands, but to actually communicate with the drive, the kernel needs to know how to talk through the USB system. 

In the abstract, USB is quite similar to SCSI—it has device classes, buses, and host controllers. Therefore, it should be no surprise that
the Linux kernel includes a three-layer USB subsystem that closely resembles the SCSI subsystem, with device-class drivers at the top,
a bus management core in the middle, and host controller 
drivers at the bottom. Much as the SCSI subsystem passes SCSI commands between its components, the USB subsystem passes USB messages
between its components. There’s even an lsusb command that is similar to lsscsi. 

The part we’re really interested in here is the USB storage driver at the top. This driver acts as a translator. On one side,
the driver speaks SCSI, and on the other, it speaks USB. Because the storage hardware includes SCSI commands inside its USB messages,
the driver has a relatively easy job: It mostly repackages data. 

With both the SCSI and USB subsystems in place, you have almost everything you need to talk to the flash drive. The final missing
link is the lower-layer driver in the SCSI subsystem because the USB storage driver is a part of the USB subsystem, not the SCSI subsystem.
(For organizational reasons, the two subsystems should not share a driver.) To get the subsystems to talk to one another, a simple,
lower-layer SCSI bridge driver connects to the USB subsystem’s storage driver.

                                          SCSI and ATA 
The SATA hard disk and optical drive shown in Figure 3-2 both use the same SATA interface. To connect the SATA-specific drivers of the
kernel to the SCSI subsystem, the kernel employs a bridge driver, as with the ,
USB drives, but with a different mechanism and additional complications. The optical drive speaks ATAPI, a version of SCSI commands
encoded in the ATA protocol. However, the hard disk does not use ATAPI and does not encode any SCSI commands! 

The Linux kernel uses part of a library called libata to reconcile SATA (and ATA) drives with the SCSI subsystem. For the
ATAPI-speaking optical drives, this is a relatively simple task of packaging and extracting 

SCSI commands into and from the ATA protocol. But for the hard disk, the task is much more complicated 
because the library must do a full command translation. 

The job of the optical drive is similar to typing an English book into a computer. You don’t need to understand what the book is
about in order to do this job, nor do you even need to understand English. But the task for the hard disk is more like reading a German book
and typing it into the computer as an English translation. In this case, you need to understand both languages as well as the book’s content.
 
Despite this difficulty, libata performs this task and makes it possible to attach the SCSI subsystem to ATA/SATA interfaces and devices.
(There are typically more drivers involved than just the one SATA host driver shown in Figure 3-2, but they’re not shown for the sake of simplicity.)


Generic SCSI Devices 
When a user-space process communicates with the SCSI subsystem, it normally does so through the block 
device layer and/or another other kernel service that sits on top of an SCSI device class driver (like sd or sr). 
In other words, most user processes never need to know anything about SCSI devices or their commands. 
However, user processes can bypass device class drivers and give SCSI protocol commands directly to devices 
through their generic devices. For example, consider the system described in 3.6 In-Depth: SCSI and the Linux 
Kernel, but this time, take a look at what happens when you add the -g option to lsscsi in order to show 
the generic devices: 
$ lsscsi -g 
[0:0:0:0] disk ATA WDC WD3200AAJS-2 01.0 /dev/sda ➊/dev/sg0 
[1:0:0:0] cd/dvd Slimtype DVD A DS8A5SH XA15 /dev/sr0 /dev/sg1 
[2:0:0:0] disk USB2.0 CardReader CF 0100 /dev/sdb /dev/sg2 
[2:0:0:1] disk USB2.0 CardReader SM XD 0100 /dev/sdc /dev/sg3 
[2:0:0:2] disk USB2.0 CardReader MS 0100 /dev/sdd /dev/sg4 
[2:0:0:3] disk USB2.0 CardReader SD 0100 /dev/sde /dev/sg5 
[3:0:0:0] disk FLASH Drive UT_USB20 0.00 /dev/sdf /dev/sg6 

In addition to the usual block device file, each entry lists an SCSI generic device file in the last column at ➊. 
For example, the generic device for the optical drive at /dev/sr0 is /dev/sg1. 

Why would you want to use an SCSI generic device? The answer has to do with the complexity of code in the kernel. As tasks
get more complicated, it’s better to leave them out of the kernel. Consider CD/DVD writing and reading. Not only is writing
significantly more difficult than reading, but no critical system services depend on the action of writing. A user-space program
might do the writing a little more inefficiently than a kernel service, but that program will be far easier to build and maintain
than a kernel service, and bugs will 
not threaten kernel space. Therefore, to write to an optical disc in Linux, you run a program that talks to a generic SCSI device,
such as /dev/sg1. Due to the relative simplicity of reading compared to writing, however, you still read from the device using the
specialized sr optical device driver in the kernel.


Multiple Access Methods for a Single Device 
The two points of access (sr and sg) for an optical drive from user space are illustrated for the Linux SCSI 
subsystem in Figure 3-3 (any drivers below the SCSI lower layer have been omitted). Process A reads from 
the drive using the sr driver, and process B writes to the drive with the sg driver. However, processes such as these two would not normally
run simultaneously to access the same device.


Disks and Filesystems 

In Chapter 3, we discussed some of the top-level disk devices that the kernel makes available. In this chapter, we’ll discuss in detail how to work with disks
on a Linux system. You’ll learn how to partition disks, create and maintain the filesystems that go inside disk partitions, and work with swap space. 

Recall that disk devices have names like /dev/sda, the first SCSI subsystem disk. This kind of block device represents the entire disk, but there are many
different components and layers inside a disk. 

Figure 4-1 illustrates the schematic of a typical Linux disk (note that the figure is not to scale). As you progress through this chapter, you’ll learn where
each piece fits in.iii

Partitions are subdivisions of the whole disk. On Linux, they’re denoted with a number after the whole block device, and therefore have device names
such as /dev/sda1 and /dev/sdb3. The kernel presents each partition as a block device, just as it would an entire disk. Partitions are defined on a small
area of the disk called a partition table. 

                                                 NOTE 
Multiple data partitions were once common on systems with large disks because older PCs could 
boot only from certain parts of the disk. Also, administrators used partitions to reserve a certain 
amount of space for operating system areas; for example, they didn’t want users to be able to fill 
up the entire system and prevent critical services from working. This practice is not unique to Unix; 
you’ll still find many new Windows systems with several partitions on a single disk. In addition, most systems have a separate swap partition. 

Although the kernel makes it possible for you to access both an entire disk and one of its partitions at the same time, you would not normally do so,
unless you were copying the entire disk. 

The next layer after the partition is the filesystem, the database of files and directories that you’re accustomed to interacting with in user space.
We’ll explore filesystems in 4.2 Filesystems. 

As you can see in Figure 4-1, if you want to access the data in a file, you need to get the appropriate partition location from the partition table and
then search the filesystem database on that partition for the desired file data. 

To access data on a disk, the Linux kernel uses the system of layers shown in Figure 4-2. The SCSI subsystem and everything else described in 3.6 In-Depth:
SCSI and the Linux Kernel are represented by a single box. 

(Notice that you can work with the disk through the filesystem as well as directly through the disk devices. 
You’ll do both in this chapter.)

To get a handle on how everything fits together, let’s start at the bottom with partitions.

Partitioning Disk Devices 

There are many kinds of partition tables. The traditional table is the one found inside the Master Boot Record (MBR). A newer standard starting to gain
traction is the Globally Unique Identifier Partition Table (GPT). 
Here is an overview of the many Linux partitioning tools available: 

o parted A text-based tool that supports both MBR and GPT. 
o gparted A graphical version of parted. 

o fdisk The traditional text-based Linux disk partitioning tool. fdisk does not support GPT. 

o gdisk A version of fdisk that supports GPT but not MBR. 
Because it supports both MBR and GPT, we’ll use parted in this book. However, many people prefer the 
fdisk interface, and there’s nothing wrong with that. 


                                                            NOTE 
Although parted can create and resize filesystems, you shouldn’t use it for filesystem manipulation because you can easily get confused. There is a
critical difference between partitioning and filesystem manipulation. The partition table defines simple boundaries on the disk, whereas a filesystem
is a much more involved data system. For this reason, we’ll use parted for partitioning but use separate utilities for creating filesystems (see 4.2.2 Creating a Filesystem). 

Even the parted documentation encourages you to create filesystems separately.

Viewing a Partition Table 

You can view your system’s partition table with parted -l. Here is sample output from two disk devices with two different kinds of partition tables: 

# parted -l 

Model: ATA WDC WD3200AAJS-2 (scsi) 

Disk /dev/sda: 320GB 

Sector size (logical/physical): 512B/512B 

Partition Table: msdos 

Number Start End Size Type File system Flags 

1 1049kB 316GB 316GB primary ext4 boot 

2 316GB 320GB 4235MB extended 

5 316GB 320GB 4235MB logical linux-swap(v1) 

Model: FLASH Drive UT_USB20 (scsi) 

Disk /dev/sdf: 4041MB 

Sector size (logical/physical): 512B/512B 

Partition Table: gpt 

Number Start End Size File system Name Flags 

1 17.4kB 1000MB 1000MB myfirst 

2 1000MB 4040MB 3040MB mysecond

The first device, /dev/sda, uses the traditional MBR partition table (called “msdos” by parted), and the 
second contains a GPT table. Notice that there are different parameters for each partition table, because the tables themselves are different. In particular,
there is no Name column for the MBR table because names don’t exist under that scheme. (I arbitrarily chose the names myfirst and mysecond in the GPT table.) 

The MBR table in this example contains primary, extended, and logical partitions. A primary partition is a normal subdivision of the disk; partition 1
is such a partition. The basic MBR has a limit of four primary partitions, so if you want more than four, you designate one partition as an extended partition.
Next, you subdivide the extended partition into logical partitions that the operating system can use as it would any other partition. In this example,
partition 2 is an extended partition that contains logical partition 5. 

                                                           NOTE 
The filesystem that parted lists is not necessarily the system ID field defined in most MBR entries. The MBR system ID is just a number; for example,
83 is a Linux partition and 82 is Linux swap. 

Therefore, parted attempts to determine a filesystem on its own. If you absolutely must know the system ID for an MBR, use fdisk -l. 

Initial Kernel Read 
When initially reading the MBR table, the Linux kernel produces the following debugging output (remember that you can view this with dmesg): 

sda: sda1 sda2 < sda5 > 
The sda2 < sda5 > output indicates that /dev/sda2 is an extended partition containing one logical partition, /dev/sda5. 

You’ll normally ignore extended partitions because you’ll typically want to access only the logical partitions inside.

Changing Partition Tables 

Viewing partition tables is a relatively simple and harmless operation. Altering partition tables is also relatively easy, but there are risks involved in
making this kind of change to the disk. Keep the following in mind: 

o Changing the partition table makes it quite difficult to recover any data on partitions that you delete because it changes the initial point of reference
for a filesystem. Make sure that you have a backup if the disk you’re partitioning contains critical data. 

o Ensure that no partitions on your target disk are currently in use. This is a concern because most Linux 
distributions automatically mount any detected filesystem. (See 4.2.3 Mounting a Filesystem for more on 
mounting and unmounting.) 
When you’re ready, choose your partitioning program. If you’d like to use parted, you can use the 
command-line parted utility or a graphical interface such as gparted; for an fdisk-style interface, use 
gdisk if you’re using GPT partitioning. These utilities all have online help and are easy to learn. (Try using them on a flash device or something similar
if you don’t have any spare disks.) 

That said, there is a major difference in the way that fdisk and parted work. With fdisk, you design 
your new partition table before making the actual changes to the disk; fdisk only makes the changes as you exit the program. But with parted, partitions
are created, modified, and removed as you issue the commands. 

You don’t get the chance to review the partition table before you change it. 

These differences are also important to understanding how these two utilities interact with the kernel. Both fdisk and parted modify the partitions
entirely in user space; there is no need to provide kernel support for rewriting a partition table because user space can read and modify all of a block device. 
Eventually, though, the kernel must read the partition table in order to present 

the partitions as block devices. 

The fdisk utility uses a relatively simple method: After modifying the partition table, fdisk issues a single 
system call on the disk to tell the kernel that it should reread the partition table. The kernel then generates debugging output that you can view with dmesg.
For example, if you create two partitions on /dev/sdf, you’ll see this: 

sdf: sdf1 sdf2 

In comparison, the parted tools do not use this disk-wide system call. Instead, they signal the kernel when 
individual partitions are altered. After processing a single partition change, the kernel does not produce the preceding debugging output. 

There are a few ways to see the partition changes: 

o Use udevadm to watch the kernel event changes. For example, udevadm monitor --kernel will 
show the old partition devices being removed and the new ones being added. 

o Check /proc/partitions for full partition information. 

o Check /sys/block/device/ for altered partition system interfaces or /dev for altered partition devices. 
If you absolutely must be sure that you have modified a partition table, you can perform the old-style system call that fdisk uses by using the
blockdev command. For example, to force the kernel to reload the partition table on /dev/sdf, run this:
 
# blockdev --rereadpt /dev/sdf 
At this point, you have all you need to know about partitioning disks. However, if you’re interested in learning a few more details about disks,
read on. Otherwise, skip ahead to 4.2 Filesystems to learn about putting a file- system on the disk.

Disk and Partition Geometry 

Any device with moving parts introduces complexity into a software system because there are physical elements that resist abstraction. A hard disk
is no exception; even though you can think of a hard disk as a block device with random access to any block, there are serious performance consequences
if you aren’t careful about how you lay out data on the disk. Consider the physical properties of the simple single-platter disk illustrated in Figure 4-3. 

The disk consists of a spinning platter on a spindle, with a head attached to a moving arm that can sweep across the radius of the disk. As the disk
spins underneath the head, the head reads data. When the arm is in one position, the head can only read data from a fixed circle. This circle is called
a cylinder because larger disks have more than one platter, all stacked and spinning around the same spindle. Each platter can have one or two heads, for
the top and/or bottom of the platter, and all heads are attached to the same arm and move in concert. Because the arm moves, there are many cylinders on the disk,
from small ones around the center to large ones around the periphery of the disk. Finally, you can divide a cylinder into slices called sectors. 

This way of thinking about the disk geometry is called CHS, for cylinder-head-sector.

A track is a part of a cylinder that a single head accesses, so in Figure 4-3, a cylinder is also a 
track. You probably don’t need to worry about tracks. 

The kernel and the various partitioning programs can tell you what a disk reports as its number of cylinders (and sectors, which are slices of cylinders).
However, on a modern hard disk, the reported values are fiction! 

The traditional addressing scheme that uses CHS doesn’t scale with modern disk hardware, nor does it account for the fact that you can put more data into outer
cylinders than inner cylinders. Disk hardware supports 
Logical Block Addressing (LBA) to simply address a location on the disk by a block number, but remnants of CHS remain. For example, the MBR partition table
contains CHS information as well as LBA equivalents, and some boot loaders are still dumb enough to believe the CHS values (don’t worry—most Linux boot loaders
use the LBA values). 
Nevertheless, the idea of cylinders has been important to partitioning because cylinders are ideal boundaries for partitions. Reading a data stream from
a cylinder is very fast because the head can continuously pick up data as the disk spins. A partition arranged as a set of adjacent cylinders also allows for
fast continuous data access because the head doesn’t need to move very far between cylinders. Some partitioning programs complain if you don’t place your
partitions precisely on cylinder boundaries. Ignore this; there’s little you can do because the reported CHS values of modern disks simply aren’t true.

 The disk’s LBA scheme ensures that your partitions are where they’re supposed to be. 

4.1.4 Solid-State Disks (SSDs) 
Storage devices with no moving parts, such as solid-state disks (SSDs), are radically different from spinning disks in terms of their access characteristics.
For these, random access is not a problem because there’s no head to sweep across a platter, but certain factors affect performance. 


One of the most significant factors affecting the performance of SSDs is partition alignment. When you read data from an SSD, you read it in chunks— typically
4096 bytes at a time—and the read must begin at a 
multiple of that same size. So if your partition and its data do not lie on a 4096-byte boundary, you may have to do two reads instead of one for small,
common operations, such as reading the contents of a directory. 

Many partitioning utilities (parted and gparted, for example) include functionality to put newly created 
partitions at the proper offsets from the beginning of the disks, so you may never need to worry about improper partition alignment. However, if you’re curious
about where your partitions begin and just want to make sure that they begin on a boundary, you can easily find this information by looking in /sys/block.
Here’s an example for a partition /dev/sdf2: 

$ cat /sys/block/sdf/sdf2/start 
1953126 

This partition starts at 1,953,126 bytes from the beginning of the disk. Because this number is not divisible by 4,096, the partition would not be attaining
optimal performance if it were on SSD.


